{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Fit (Parameter Estimation) with** ***Real Data***\n",
    "### - **Maximum Likelihood Estimation (MLE)**\n",
    "- Estimates Alpha and Gamma/Mu first, then Beta second\n",
    "\n",
    "\n",
    "#### **====Why bother using our own math for LL rather than Scipy's Bernoulli logpmf?====**\n",
    "\n",
    "- Most importantly, so we can better understand the mathematical foundation of our modeling. It is necessary to understand each part so we know when and why these components may not be appropriate or even misleading.\n",
    "    - Lets everyone know what's actually happening! Couldn't find docs explaining the \"efficiency mechanics\" of Bernoulli's logpmf, so let's investigate compare the LL outcomes:\n",
    "    - Returns identical summed LL\n",
    "        - log(x) * y == log(x**y)\n",
    "            - If you multiply a logged value by another value (*left*), it's the same as if you exponentiated before logging (*right*)\n",
    "                - *Logs are used to get the exponent required for the base to reach the input value*\n",
    "                    - z = log_e(x) --> e**z = x\n",
    "                        - z * y = y * log_e(x) --> e**(z*y) = x**y\n",
    "                            - z * y = log_e(x**y)\n",
    "        - x = prob of choosing lottery for the current condition subgroup\n",
    "        - y <= number of trials per subgroup\n",
    "        - Can be represented as log(x) + log(x) == 2 * log(x)\n",
    "            - log(x) was originally part of log(x**2)\n",
    "        - *Works regardless of number of trials per subgroup*\n",
    "    - Bernoulli:\n",
    "        - log(x) + log(x) + log(x[y number of times])\n",
    "    - Manual:\n",
    "        - log(x) * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demonstration ##\n",
    "import numpy as np\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "MLL_trials = np.array([2.0, 1.0, 1.0]) ## (y) each value represents the sum of lottery choices in that condition subgroup | number of trials per subgroup = 2\n",
    "MLL_probs  = np.array([1.0, 0.5, 0.7]) ## (p) probability (predictive - not proportion) Ss will chosVe lottery for each condition subgroup\n",
    "MLL_total_trials = np.array([2, 2, 2]) ## (previously 1) number of trials per subgroup\n",
    "print(\"No black box LL:    \", np.nansum(np.log(MLL_probs) * MLL_trials + np.log(1 - MLL_probs) * (MLL_total_trials - MLL_trials)))\n",
    "\n",
    "BLL_trials = np.array([1.0, 1.0, 0.0, 1.0, 1.0, 0.0])\n",
    "BLL_probs  = np.array([1.0, 1.0, 0.5, 0.5, 0.7, 0.7])\n",
    "print(\"Bernoulli logpmf LL:\", np.nansum(bernoulli.logpmf(BLL_trials, BLL_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===================\n",
    "Mandy Renfro (2024)\n",
    "===================\n",
    "\"\"\"\n",
    "\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.seterr(all = \"ignore\")\n",
    "import os\n",
    "import os.path, sys\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.integrate import simps, trapz\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\", palette=\"muted\")\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "base_proj_dir = \"Z:/data/SDAN/crdm\" ## base project directory\n",
    "data_dir = \"Z:/data/SDAN/crdm/sourcedata/adult\" ## directory containing adult data\n",
    "\n",
    "\n",
    "def goodness_of_fit(max_LL, choices, n = 1, num_params = 3):\n",
    "    \"\"\"Calculates goodness of fit metrics (R Squared and AIC) \n",
    "        INPUT:\n",
    "        - max_LL: maximum likelihood score associated with best fit parameters\n",
    "        - choice:\n",
    "        - n: each row containing a single trial\n",
    "        - num_params: number of free parameters (alpha, beta, & gamma)\n",
    "        OUTPUT:\n",
    "        - R2: proportion of variance in the observed data that is explained by the parameters\n",
    "        - AIC: Akaike Information Criterion for current model\n",
    "        - AIC_0: Akaike Information Criterion for strawman model\n",
    "    \"\"\"\n",
    "    strawman_MLL = np.nansum(np.log(0.5) * choices + np.log(1 - 0.5) * (n - choices))\n",
    "    maximum_LL = max_LL\n",
    "    R2 = np.round(1 - (maximum_LL/strawman_MLL), 4) \n",
    "    AIC = np.round((2 * num_params) - (2 * maximum_LL), 4)\n",
    "    AIC_0 = np.round((2 * 0) - (2 * strawman_MLL), 4)\n",
    "    return R2, AIC, AIC_0\n",
    "\n",
    "\n",
    "def pd_extend(df_dest, df_extending):\n",
    "    \"\"\" Concatenates all subjects dataframe for saving current Ss parameters\n",
    "        INPUT:\n",
    "        - df_dest: destination dataframe to which second dataframe will be appended\n",
    "        - df_extending: dataframe to be added to the destination dataframe\n",
    "        OUTPUT:\n",
    "        - Concatenated dataframe containing info from currently iterated Ss\n",
    "    \"\"\"\n",
    "    return pd.concat([df_dest, df_extending])\n",
    "\n",
    "\n",
    "def SVs(alpha, beta, lottery_value, certain_value, ambiguity, probability):\n",
    "    \"\"\" Calculate SV for lottery and safe options (Gilboa & Schmeidler, 1989)\n",
    "        **Note: np.sign() and np.abs() allows this function to flexibly handle *both* gain and loss trials\n",
    "        INPUT:\n",
    "        - alpha: current Ss alpha\n",
    "        - beta: current Ss beta\n",
    "        - lottery_value: winning lottery amount\n",
    "        - ambiguity: ambiguity level\n",
    "        - probability: probability level\n",
    "        OUTPUT:\n",
    "        - SV_lottery: subjective value for lottery option\n",
    "        - SV_certain: subjective value for certain option\n",
    "    \"\"\"\n",
    "    SV_lottery = (probability - beta * ambiguity / 2) * np.sign(lottery_value) * (np.abs(lottery_value)**alpha)\n",
    "    SV_certain = np.sign(certain_value) * (np.abs(certain_value)**alpha)\n",
    "    return SV_lottery, SV_certain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Softmax Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_likelihood_SM(alpha, beta, gamma, y, n, lottery_value, certain_value, ambiguity, probability):\n",
    "    \"\"\" Calculates binomial LL for each parameter combination\n",
    "        *See above notes for why we can use our own math rather than rely on bernoulli.logpmf()\n",
    "        *Deals with positive infinity values by assigning a value of 0, \n",
    "        then during MLE functions, parameter pairs with 0 LL score are removed\n",
    "        INPUT:\n",
    "        - alpha: current Ss risk parameter [high values indicate risk seeking]\n",
    "        - beta: current Ss ambiguity parameter [high values indicate ambiguity avoidance]\n",
    "        - gamma: current Ss choice stochasticity parameter [high values indicate more noise]\n",
    "        - y: summation of lottery choices\n",
    "        - n: number of trials\n",
    "        - lottery_value: all lottery values for risk or ambiguity trials \n",
    "        - certain_value: all safe values for risk or ambiguity trials \n",
    "        - ambiguity: all ambiguity values for risk (amb = 0) or ambiguity trials\n",
    "        - probability: all probability values for risk or ambiguity (prob = 0.5) trials\n",
    "        OUTPUT:\n",
    "        - log_likelihood: relative likeliness score representing probabilty observed data resulted from current parameter combo\n",
    "    \"\"\"\n",
    "    p = probability_of_lottery_choice_SM(alpha, beta, gamma, lottery_value, certain_value, ambiguity, probability)\n",
    "    log_likelihood = (np.log(p) * y + np.log(1 - p) * (n - y))\n",
    "    log_likelihood[log_likelihood == np.inf] = 0\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def fit_data_SM(data, session, domain, pid, df):\n",
    "    \"\"\" (1) Calls MLE functions to fit model and return Alpha, Gamma, and Beta parameters\n",
    "        (2) Creates dataframe for saving parameter estimates\n",
    "        INPUTS:\n",
    "        - data: current Ss dataframe containing trial data (domain, prob, amb, sure_amt, lott_amt, choice)\n",
    "        - session: experiment session\n",
    "        - domain: run separately for gain/loss trials\n",
    "        - pid: current subject ID\n",
    "        - df: dataframe (df_participants) to which the current Ss data will be appended\n",
    "        OUTPUT:\n",
    "        - *res: packed variable representing current Ss alpha, beta, and gamma for gain or loss domain\n",
    "        - df: df_participants appended to include Ss fitted parameters\n",
    "    \"\"\"\n",
    "    choices = data[\"choice\"].values\n",
    "    lotteries = data[\"lott_amt\"].values\n",
    "    certain_values = data[\"sure_amt\"].values\n",
    "    ambiguities = data[\"amb\"].values/100\n",
    "    probabilities = data[\"prob\"].values/100\n",
    "    res = MLE_alpha_gamma_SM(choices, lotteries, certain_values, ambiguities, probabilities)\n",
    "    res, max_LL = MLE_beta_SM(choices, res[0], res[1], lotteries, certain_values, ambiguities, probabilities)\n",
    "    gof = goodness_of_fit(max_LL, choices)\n",
    "    df = pd_extend(df, pd.DataFrame(np.array([pid, session, domain, *res, np.round(max_LL, 4), *gof]).reshape(1, -1), columns = df.columns))\n",
    "    return *res, df\n",
    "\n",
    "\n",
    "def MLE_alpha_gamma_SM(choices, lotteries, certain_values, ambiguities, probabilities):\n",
    "    \"\"\" Grid search of alpha and gamma parameter space to determine which point produces max log likelihood score. \n",
    "        *Risk trials only*\n",
    "        *Notes: Conceptualize parameter and probability space as two parallel multidimensional spaces. \n",
    "                Using a \"grid search\" method, we carefully iterate through a 2D parameter space (alpha/gamma) \n",
    "                to determine which point best explains the data, quantified as the maximum likelihood score.\n",
    "        INPUT:\n",
    "        ** Numpy parallel arrays **\n",
    "        - choices: Ss choices\n",
    "        - lotteries: winning lottery amounts\n",
    "        - certain_values: certain amounts\n",
    "        - ambiguities: ambiguity level\n",
    "        - probabilities: probability level\n",
    "        OUTPUT:\n",
    "        - best_fit: Tuple containing best fit parameters (alpha and gamma)\n",
    "    \"\"\"\n",
    "    best_fit = None\n",
    "    max_likelihood = None\n",
    "    x, n = choices, np.ones(choices.shape)\n",
    "    idx = np.where(ambiguities == 0)\n",
    "    for alpha in np.round(np.arange(0.3, 2, 0.01), 2): ## Grid Search 1 (search through 2D: alpha and gamma)\n",
    "        for gamma in np.round(np.arange(0.01, 8, 0.01), 2):\n",
    "            ## Summation of log likelihoods for all trials (beta/ambiguity held constant at 0 | only risk trials)\n",
    "            likelihood = np.nansum(binomial_likelihood_SM(alpha, 0, gamma, x[idx], n[idx], lotteries[idx], \n",
    "                                                            certain_values[idx], ambiguities[idx], probabilities[idx]))\n",
    "            if max_likelihood is None or likelihood > max_likelihood:\n",
    "                max_likelihood = likelihood\n",
    "                best_fit = (alpha, gamma)\n",
    "    return best_fit\n",
    "\n",
    "\n",
    "def MLE_beta_SM(choices, alpha, gamma, lotteries, certain_values, ambiguities, probabilities):\n",
    "    \"\"\" Grid search of beta parameter space to determine which point produces max log likelihood score. \n",
    "        *Ambiguity trials only*\n",
    "        *Notes: Conceptualize parameter and probability space as two parallel multidimensional spaces. \n",
    "                Using a \"grid search\" method previously to determine the best fit of alpha and gamma parameters, \n",
    "                we can use those values to now guide our search through 1D beta space.\n",
    "        INPUT:\n",
    "        ** Numpy parallel arrays **\n",
    "        - choices: Ss choices\n",
    "        - lotteries: winning lottery amounts\n",
    "        - certain_values: certain amounts\n",
    "        - ambiguities: ambiguity level\n",
    "        - probabilities: probability level\n",
    "        OUTPUT:\n",
    "        - best_fit: Tuple containing best fit parameters (alpha, beta, and gamma)\n",
    "        - max_likelihood: Maximum log likelihood associated with best fit parameters\n",
    "    \"\"\"\n",
    "    best_fit = None\n",
    "    max_likelihood = None\n",
    "    x, n = choices, np.ones(choices.shape)\n",
    "    idx = np.where(ambiguities != 0)\n",
    "    for beta in np.round(np.arange(-1.3, 1.31, 0.01), 2): ## Grid Search 2 (search through 1D: beta)\n",
    "        ## Summation log likelihoods of all trials (pre-fit alpha/gamma included to inform search | only ambiguity trials)\n",
    "        likelihood = np.nansum(binomial_likelihood_SM(alpha, beta, gamma, x[idx], n[idx], lotteries[idx], \n",
    "                                                        certain_values[idx], ambiguities[idx], probabilities[idx]))\n",
    "        if max_likelihood is None or likelihood > max_likelihood:\n",
    "            max_likelihood = likelihood\n",
    "            best_fit = (alpha, beta, gamma)\n",
    "    return best_fit, max_likelihood\n",
    "\n",
    "\n",
    "def probability_of_lottery_choice_SM(alpha, beta, gamma, lottery_value, certain_value, ambiguity, probability):\n",
    "    \"\"\" Determines probability of selecting lottery using the Softmax probabilitic function\n",
    "        INPUT:\n",
    "        - alpha: current Ss risk parameter [high values indicate risk seeking]\n",
    "        - beta: current Ss ambiguity parameter [high values indicate ambiguity avoidance]\n",
    "        - gamma: current Ss choice stochasticity parameter [high values indicate more noise]\n",
    "        - lottery_value: all lottery values for risk or ambiguity trials \n",
    "        - certain_value: all safe values for risk or ambiguity trials \n",
    "        - ambiguity: all ambiguity values for risk (amb = 0) or ambiguity trials\n",
    "        - probability: all probability values for risk or ambiguity (prob = 0.5) trials\n",
    "        OUTPUT:\n",
    "        - Ss probability of choosing lottery for trials with the current condition combination \n",
    "    \"\"\"\n",
    "    SV_lottery, SV_certain = SVs(alpha, beta, lottery_value, certain_value, ambiguity, probability)\n",
    "    return 1 / (1 + np.exp(-gamma * (SV_lottery - SV_certain)))\n",
    "\n",
    "\n",
    "def SVdelta_plotSM(data, idx, session, domain, pid, alpha, beta, gamma):\n",
    "    \"\"\" Plots Ss choice across SV difference space.\n",
    "        INPUT\n",
    "        - data: current Ss dataframe containing trial data (domain, prob, amb, sure_amt, lott_amt, choice)\n",
    "        - idx: current Ss idx number amongst all subjects\n",
    "        - pid: current sibject ID\n",
    "        - alpha: current Ss best fit alpha\n",
    "        - beta: current Ss best fit beta\n",
    "        - gamma: current Ss best fit gamma\n",
    "        OUTPUT\n",
    "        - plt: Psychometric choice curve demonstrating choice behavior across subject-specific SVΔ range\n",
    "    \"\"\"\n",
    "    plt.figure(idx, figsize = (6, 4))\n",
    "    choices = data[\"choice\"].values\n",
    "    lottery_values = data[\"lott_amt\"].values\n",
    "    certain_values = data[\"sure_amt\"].values\n",
    "    ambiguities = data[\"amb\"].values/100\n",
    "    probabilities = data[\"prob\"].values/100\n",
    "    SV_lottery, SV_certain = SVs(alpha, beta, lottery_values, certain_values, ambiguities, probabilities)\n",
    "    SV_delta = SV_lottery - SV_certain\n",
    "    sv_choice_tups = list(zip(SV_delta, choices))\n",
    "    sv_choice_tups = sorted(list(set(sv_choice_tups)))\n",
    "    para_deltas, para_choices = list(zip(*sorted(sv_choice_tups)))\n",
    "    SV_fit = np.linspace(min(SV_delta), max(SV_delta), 300)\n",
    "    prob_fit = []\n",
    "    for sv in SV_fit:\n",
    "        prob_fit.append(1 / (1 + np.exp(-gamma * (sv - 0))))\n",
    "    plt.plot([min(SV_delta), max(SV_delta)], [0.5, 0.5], 'k--')\n",
    "    plt.plot(SV_fit, prob_fit, \"b-\")\n",
    "    plt.plot(para_deltas, para_choices, \"ro-\")\n",
    "    plt.xlabel(\"SVΔ (Lottery-Certain)\", fontsize = 12)\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.yticks([0, 0.5, 1], [\"Certain (0)\", \"PSE (0.5)\", \"Lottery (1)\"])\n",
    "    plt.ylabel(\"Probability of Lottery Choice\", fontsize = 12)\n",
    "    sns.despine(top = True)\n",
    "    plt.title(\"SDAN sub-\" + pid + \" {0}-{1} | α = {2}, β = {3}, ɣ = {4}\".format(session, domain, alpha, beta, gamma), fontsize = 12)\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_proj_dir = os.path.join(base_proj_dir, \"derivatives/adult/parameter_estimation/softmax1\") ## output directory\n",
    "\n",
    "subs = [] ## list to store subject IDs\n",
    "descriptives = {}\n",
    "\n",
    "for i in [\"gain\", \"loss\", \"combined\"]:\n",
    "        for j in [\"resp_rate\", \"prop_lott_risk\", \"prop_lott_amb\", \"prop_lott_all\",\n",
    "                    \"conf1_ct\", \"conf2_ct\", \"conf3_ct\", \"conf4_ct\", \"conf_mean\", \"at_bound\"]:\n",
    "            descriptives[\"{0}_{1}\".format(j, i)] = []\n",
    "\n",
    "df_participants = pd.DataFrame(columns = [\"SubID\", \"Session\", \"Domain\", ## Ss parameters dataframe\n",
    "                                            \"Alpha\", \"Beta\", \"Gamma\", \n",
    "                                            \"MaxLL\", \"R2\", \"AIC\", \"AIC0\"]) \n",
    "\n",
    "files = sorted(glob(os.path.join(data_dir, \"*.csv\"))) ## grab all participant datafiles\n",
    "for curr_file in files: ## iterate through globbed files and save subject ID to a list\n",
    "    sub_id = os.path.basename(curr_file)[:5] ## grab first 5 indices of filename string\n",
    "    if not sub_id in subs: ## check if already in list\n",
    "        subs.append(sub_id) ## if not, append new Ss ID to list\n",
    "\n",
    "for idx, sub in enumerate(subs): ## iterate through Ss ID list\n",
    "    save_sub_dir = os.path.join(save_proj_dir, \"sub-{0}\".format(sub)) ## output directory\n",
    "    if not os.path.exists(save_sub_dir): ## new Ss\n",
    "        os.makedirs(save_sub_dir) ## make new Ss save directory\n",
    "    sub_files = sorted(glob(os.path.join(data_dir, \"{0}*_crdm.csv\".format(sub)))) ## files for current Ss\n",
    "    sub_cols = [\"domain\", \"prob\", \"amb\", \"sure_amt\", \"lott_amt\", \"choice\"] ## trial variables\n",
    "    sub_df = pd.DataFrame(columns = sub_cols) ## subject-specific dataframe w/ preset columns\n",
    "    if len(sub_files) == 1: ## if Ss has only 1 file\n",
    "        continue ## bad Ss, move on \n",
    "    else:  ## Ss has two data files\n",
    "        for i in range(1, -1, -1): ## go through data files in reverse order\n",
    "            raw_df = pd.read_csv(sub_files[i]) ## open current data file\n",
    "            df = raw_df.loc[(raw_df[\"crdm_trial_type\"] == \"task\") & (raw_df[\"crdm_choice\"].notnull())] ## only task trials w/ responses\n",
    "            sub_df[\"domain\"] = df[\"crdm_domain\"] ## trial type (gain/loss)\n",
    "            sub_df[\"prob\"] = df[\"crdm_lott_p\"] ## trial probability\n",
    "            sub_df[\"amb\"] = df[\"crdm_amb_lev\"] ## trial ambiguity\n",
    "            sub_df[\"sure_amt\"] = df[\"crdm_sure_amt\"] ## trial certain amount\n",
    "            sub_df[\"lott_amt\"] = df[\"crdm_lott_top\"] + df[\"crdm_lott_bot\"] ## trial lottery amount\n",
    "            sub_df[\"choice\"] = df[\"crdm_choice\"] ## trial choice (-1 = nonresponse, 0 = certain, 1 = lottery)\n",
    "            sub_gains = sub_df.loc[(sub_df[\"domain\"] == \"gain\")] ## DF with only gain trials\n",
    "            sub_losses = sub_df.loc[(sub_df[\"domain\"] == \"loss\")] ## DF with only loss trials\n",
    "            df_dict = {\"gain\": sub_gains, \"loss\": sub_losses, \"combined\": sub_df}\n",
    "            if i == 1: ## 1st data file in sorted sub_files list (stable = SESSION 1)\n",
    "                gf_alpha, gf_beta, gf_gamma, df_participants = fit_data_SM(sub_gains, \"S1\", \"gain\", sub, df_participants)\n",
    "                plt1 = SVdelta_plotSM(sub_gains, idx, \"S1\", \"Gain\", sub, gf_alpha, gf_beta, gf_gamma)\n",
    "                fig_save1 = os.path.join(save_sub_dir, \"sub-{}_sdan-crdm-sm_svdelta-choice-curve-gain1.png\".format(subs[idx]))\n",
    "                plt1.savefig(fig_save1)\n",
    "                plt1.show()\n",
    "                lf_alpha, lf_beta, lf_gamma, df_participants = fit_data_SM(sub_losses, \"S1\", \"loss\", sub, df_participants)\n",
    "                plt2 = SVdelta_plotSM(sub_losses, idx, \"S1\", \"Loss\", sub, lf_alpha, lf_beta, lf_gamma)\n",
    "                fig_save2 = os.path.join(save_sub_dir, \"sub-{}_sdan-crdm-sm_svdelta-choice-curve-loss1.png\".format(subs[idx]))\n",
    "                plt2.savefig(fig_save2)\n",
    "                plt2.show()\n",
    "                cf_alpha, cf_beta, cf_gamma, df_participants = fit_data_SM(sub_df, \"S1\", \"both\", sub, df_participants)\n",
    "                plt3 = SVdelta_plotSM(sub_df, idx, \"S1\", \"Combined\", sub, cf_alpha, cf_beta, cf_gamma)\n",
    "                fig_save3 = os.path.join(save_sub_dir, \"sub-{}_sdan-crdm-sm_svdelta-choice-curve-combined1.png\".format(subs[idx]))\n",
    "                plt3.savefig(fig_save3)\n",
    "                plt3.show()\n",
    "                for d in [\"gain\", \"loss\", \"combined\"]: ## 3 different parameter estimations for Session 1\n",
    "                    if d == \"combined\": ## combined parameter estimation\n",
    "                        descriptives[\"resp_rate_combined\"].append(len(df_dict[d][\"choice\"]) / len(raw_df.loc[(raw_df[\"crdm_trial_type\"] == \"task\")]))\n",
    "                    else: ## gain and loss parameter estimations\n",
    "                        descriptives[\"resp_rate_{0}\".format(d)].append(len(df_dict[d][\"choice\"]) / len(raw_df.loc[(raw_df[\"crdm_domain\"] == \"{0}\".format(d)) \n",
    "                                                                                                                    & (raw_df[\"crdm_trial_type\"] == \"task\")]))\n",
    "                    descriptives[\"prop_lott_risk_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"amb\"] == 0) \n",
    "                                                                        & (df_dict[d][\"choice\"] == 1)]) / len((df_dict[d][\"amb\"] == 0)))\n",
    "                    descriptives[\"prop_lott_amb_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"amb\"] != 0) \n",
    "                                                                        & (df_dict[d][\"choice\"] == 1)]) / len((df_dict[d][\"amb\"] != 0)))\n",
    "                    descriptives[\"prop_lott_all_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"choice\"] == 1)]) / len(df_dict[d][\"choice\"]))\n",
    "                    descriptives[\"conf1_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 1)]))\n",
    "                    descriptives[\"conf2_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 2)]))\n",
    "                    descriptives[\"conf3_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 3)]))\n",
    "                    descriptives[\"conf4_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 4)]))\n",
    "                    descriptives[\"conf_mean_{0}\".format(d)].append(np.nanmean(df[\"crdm_conf_resp.keys\"])) ## nanmean to exclude non-responses\n",
    "                    if gf_alpha <= 0.11 or gf_alpha >= 1.99 or gf_beta <= -1.29 or gf_beta >= 1.29 or gf_gamma <= 0.01 or gf_gamma >= 7.99:\n",
    "                        descriptives[\"at_bound_{0}\".format(d)].append(1) ## indicates Ss value at parameter bounds\n",
    "                    else:\n",
    "                        descriptives[\"at_bound_{0}\".format(d)].append(0) ## indicates Ss value not at parameter bounds\n",
    "            else: ## 2nd data file in sorted sub_files list (adaptive = SESSION 2)\n",
    "                gf_alpha, gf_beta, gf_gamma, df_participants = fit_data_SM(sub_gains, \"S2\", \"gain\", sub, df_participants)\n",
    "                plt1 = SVdelta_plotSM(sub_gains, idx, \"S2\", \"Gain\", sub, gf_alpha, gf_beta, gf_gamma)\n",
    "                fig_save1 = os.path.join(save_sub_dir, \"sub-{}_sdan-crdm-sm_svdelta-choice-curve-gain2.png\".format(subs[idx]))\n",
    "                plt1.savefig(fig_save1)\n",
    "                plt1.show()\n",
    "                lf_alpha, lf_beta, lf_gamma, df_participants = fit_data_SM(sub_losses, \"S2\", \"loss\", sub, df_participants)\n",
    "                plt2 = SVdelta_plotSM(sub_losses, idx, \"S2\", \"Loss\", sub, lf_alpha, lf_beta, lf_gamma)\n",
    "                fig_save2 = os.path.join(save_sub_dir, \"sub-{}_sdan-crdm-sm_svdelta-choice-curve-loss2.png\".format(subs[idx]))\n",
    "                plt2.savefig(fig_save2)\n",
    "                plt2.show()\n",
    "                cf_alpha, cf_beta, cf_gamma, df_participants = fit_data_SM(sub_df, \"S2\", \"both\", sub, df_participants)\n",
    "                plt3 = SVdelta_plotSM(sub_df, idx, \"S2\", \"Combined\", sub, cf_alpha, cf_beta, cf_gamma)\n",
    "                fig_save3 = os.path.join(save_sub_dir, \"sub-{}_sdan-crdm-sm_svdelta-choice-curve-combined2.png\".format(subs[idx]))\n",
    "                plt3.savefig(fig_save3)\n",
    "                plt3.show()\n",
    "                for d in [\"gain\", \"loss\", \"combined\"]: ## 3 different parameter estimations for Session 2\n",
    "                    if d == \"combined\":\n",
    "                        descriptives[\"resp_rate_combined\"].append(len(df_dict[d][\"choice\"]) / len(raw_df.loc[(raw_df[\"crdm_trial_type\"] == \"task\")]))\n",
    "                    else:\n",
    "                        descriptives[\"resp_rate_{0}\".format(d)].append(len(df_dict[d][\"choice\"]) / len(raw_df.loc[(raw_df[\"crdm_domain\"] == \"{0}\".format(d)) \n",
    "                                                                                                                    & (raw_df[\"crdm_trial_type\"] == \"task\")]))\n",
    "                    descriptives[\"prop_lott_risk_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"amb\"] == 0) \n",
    "                                                                        & (df_dict[d][\"choice\"] == 1)]) / len((df_dict[d][\"amb\"] == 0)))\n",
    "                    descriptives[\"prop_lott_amb_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"amb\"] != 0) \n",
    "                                                                        & (df_dict[d][\"choice\"] == 1)]) / len((df_dict[d][\"amb\"] != 0)))\n",
    "                    descriptives[\"prop_lott_all_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"choice\"] == 1)]) / len(df_dict[d][\"choice\"]))\n",
    "                    descriptives[\"conf1_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 1)]))\n",
    "                    descriptives[\"conf2_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 2)]))\n",
    "                    descriptives[\"conf3_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 3)]))\n",
    "                    descriptives[\"conf4_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 4)]))\n",
    "                    descriptives[\"conf_mean_{0}\".format(d)].append(np.nanmean(df[\"crdm_conf_resp.keys\"])) ## nanmean to exclude non-responses\n",
    "                    if gf_alpha <= 0.11 or gf_alpha >= 1.99 or gf_beta <= -1.29 or gf_beta >= 1.29 or gf_gamma <= 0.01 or gf_gamma >= 7.99:\n",
    "                        descriptives[\"at_bound_{0}\".format(d)].append(1) ## indicates Ss value at parameter bounds\n",
    "                    else:\n",
    "                        descriptives[\"at_bound_{0}\".format(d)].append(0) ## indicates Ss alue not at parameter bounds\n",
    "    print(sub, end = \"\\r\") ## print current Ss as output (indication of speed and where things might get hung up)\n",
    "#print(df_participants) ## df_participants has two rows per Ss: parameters for (1) gains and (2) losses. Needs reformatting\n",
    "\n",
    "## reformat dataframe to be more legible and easier to parse \n",
    "idxG = np.where(df_participants[\"Domain\"].values == \"gain\")[0] ## indices for gain parameter rows\n",
    "idxL = np.where(df_participants[\"Domain\"].values == \"loss\")[0] ## indices for loss parameter rows\n",
    "idxC = np.where(df_participants[\"Domain\"].values == \"both\")[0] ## indices for loss parameter rows\n",
    "\n",
    "## reorganized by horizonally stacking domains\n",
    "stacked_data = np.hstack((df_participants.values[idxG], df_participants.values[idxL], df_participants.values[idxC])) \n",
    "#print(stacked_data[0]) ## new DF format\n",
    "## temporary dataframe with hstacked data, tagging rows to drop with \"d#\"\n",
    "temp_df = pd.DataFrame(stacked_data, columns = [\"PID\", \"Session\", \n",
    "                                                \"d1\",\n",
    "                                                \"Alpha-G\", \"Beta-G\", \"Gamma-G\", \"MLL-G\", \"R2-G\", \"AIC-G\", \"AIC0-G\", \n",
    "                                                \"d2\", \"d3\", \"d4\", \n",
    "                                                \"Alpha-L\", \"Beta-L\", \"Gamma-L\", \"MLL-L\", \"R2-L\", \"AIC-L\", \"AIC0-L\",\n",
    "                                                \"d5\", \"d6\", \"d7\",\n",
    "                                                \"Alpha-C\", \"Beta-C\", \"Gamma-C\", \"MLL-C\", \"R2-C\", \"AIC-C\", \"AIC0-C\"])\n",
    "## redeclare df_participants variable with temp_df while dropping unwanted columns (i.e., \"gain\", Ss # repeat, \"loss\")\n",
    "df_participants = temp_df.drop([\"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\"], axis = 1) \n",
    "\n",
    "dom = [\"G\", \"L\", \"C\"]\n",
    "for i, d in enumerate([\"gain\", \"loss\", \"combined\"]):\n",
    "    df_participants[\"RespRate-{0}\".format(dom[i])] = np.round(descriptives[\"resp_rate_{0}\".format(d)], 2) ## proportion of trials Ss responded\n",
    "    df_participants[\"RiskLottC-{0}\".format(dom[i])] = np.round(descriptives[\"prop_lott_risk_{0}\".format(d)], 2) ## proportion of risk trials Ss chose lottery\n",
    "    df_participants[\"AmbigLottC-{0}\".format(dom[i])] = np.round(descriptives[\"prop_lott_amb_{0}\".format(d)], 2) ## proportion of ambiguity trials Ss chose lottery\n",
    "    df_participants[\"AllLottC-{0}\".format(dom[i])] = np.round(descriptives[\"prop_lott_all_{0}\".format(d)], 2) ## proportion of trials Ss chose lottery\n",
    "    df_participants[\"Conf1-{0}\".format(dom[i])] = descriptives[\"conf1_ct_{0}\".format(d)] ## \"not at all confident\" count\n",
    "    df_participants[\"Conf2-{0}\".format(dom[i])] = descriptives[\"conf2_ct_{0}\".format(d)] ## \"a litte confident\" count\n",
    "    df_participants[\"Conf3-{0}\".format(dom[i])] = descriptives[\"conf3_ct_{0}\".format(d)] ## \"somewhat confident\" count\n",
    "    df_participants[\"Conf4-{0}\".format(dom[i])] = descriptives[\"conf4_ct_{0}\".format(d)] ## \"very confident\" count\n",
    "    df_participants[\"ConfAvg-{0}\".format(dom[i])] = np.round(descriptives[\"conf_mean_{0}\".format(d)], 2) ## mean confidence ratings\n",
    "    df_participants[\"ParamOut-{0}\".format(dom[i])] = descriptives[\"at_bound_{0}\".format(d)] ## parameter outlier status (boolean)\n",
    "\n",
    "filename = os.path.join(save_proj_dir, \"sdan-crdm-sm_modelfit.csv\") ## filename indicates domain and choice model\n",
    "df_participants.to_csv(filename, columns = [\"PID\", \"Session\", \"Alpha-G\", \"Beta-G\", \"Gamma-G\", \"MLL-G\", \"R2-G\", \n",
    "                                            \"AIC-G\", \"AIC0-G\", \"RespRate-G\", \"RiskLottC-G\", \"AmbigLottC-G\", \"AllLottC-G\", \n",
    "                                            \"Conf1-G\", \"Conf2-G\", \"Conf3-G\", \"Conf4-G\", \"ConfAvg-G\", \"ParamOut-G\",\n",
    "                                            \"Alpha-L\", \"Beta-L\", \"Gamma-L\", \"MLL-L\", \"R2-L\", \n",
    "                                            \"AIC-L\", \"AIC0-L\", \"RespRate-L\", \"RiskLottC-L\", \"AmbigLottC-L\", \"AllLottC-L\", \n",
    "                                            \"Conf1-L\", \"Conf2-L\", \"Conf3-L\", \"Conf4-L\", \"ConfAvg-L\", \"ParamOut-L\",\n",
    "                                            \"Alpha-C\", \"Beta-C\", \"Gamma-C\", \"MLL-C\", \"R2-C\", \n",
    "                                            \"AIC-C\", \"AIC0-C\", \"RespRate-C\", \"RiskLottC-C\", \"AmbigLottC-C\", \"AllLottC-C\", \n",
    "                                            \"Conf1-C\", \"Conf2-C\", \"Conf3-C\", \"Conf4-C\", \"ConfAvg-C\", \"ParamOut-C\"],\n",
    "                                            index = False) ## save csv without dataframe row indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Luce Model of Discrete Choice**\n",
    "\n",
    "- Does not currently produce SVDelta Choice plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_likelihood_LUCE(alpha, beta, mu, y, n, lottery_value, certain_value, ambiguity, probability):\n",
    "    p = probability_of_lottery_choice_LUCE(alpha, beta, mu, lottery_value, certain_value, ambiguity, probability)\n",
    "    log_likelihood = (np.log(p) * y + np.log(1 - p) * (n - y)) \n",
    "    log_likelihood[log_likelihood == np.inf] = 0\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def fit_data_LUCE(data, session, domain, pid, df):\n",
    "    choices = data[\"choice\"].values\n",
    "    lotteries = data[\"lott_amt\"].values\n",
    "    certain_values = data[\"sure_amt\"].values\n",
    "    ambiguities = data[\"amb\"].values/100\n",
    "    probabilities = data[\"prob\"].values/100\n",
    "    res = MLE_alpha_mu_LUCE(choices, lotteries, certain_values, ambiguities, probabilities)\n",
    "    res, max_LL = MLE_beta_LUCE(choices, res[0], res[1], lotteries, certain_values, ambiguities, probabilities)\n",
    "    gof = goodness_of_fit(max_LL, choices)\n",
    "    df = pd_extend(df, pd.DataFrame(np.array([pid, session, domain, *res, np.round(max_LL, 4), *gof]).reshape(1, -1), columns = df.columns))\n",
    "    return *res, df\n",
    "\n",
    "\n",
    "def MLE_alpha_mu_LUCE(choices, lotteries, certain_values, ambiguities, probabilities):\n",
    "    best_fit = None\n",
    "    max_likelihood = None\n",
    "    y, n = choices, np.ones(choices.shape)\n",
    "    idx = np.where(ambiguities == 0)\n",
    "    for alpha in np.round(np.arange(0.3, 2, 0.01), 2):\n",
    "        for mu in np.round(np.arange(0.01, 1, 0.01), 2):\n",
    "            likelihood = np.nansum(binomial_likelihood_LUCE(alpha, 0, mu, y[idx], n[idx], lotteries[idx], \n",
    "                                                            certain_values[idx], ambiguities[idx], probabilities[idx]))\n",
    "            if max_likelihood is None or likelihood > max_likelihood:\n",
    "                max_likelihood = likelihood\n",
    "                best_fit = (alpha, mu)\n",
    "    return best_fit\n",
    "\n",
    "\n",
    "def MLE_beta_LUCE(choices, alpha, mu, lotteries, certain_values, ambiguities, probabilities):\n",
    "    best_fit = None\n",
    "    max_likelihood = None\n",
    "    y, n = choices, np.ones(choices.shape)\n",
    "    idx = np.where(ambiguities != 0)\n",
    "    for beta in np.round(np.arange(-1.3, 1.31, 0.01), 2):\n",
    "        likelihood = np.nansum(binomial_likelihood_LUCE(alpha, beta, mu, y[idx], n[idx], lotteries[idx], \n",
    "                                                        certain_values[idx], ambiguities[idx], probabilities[idx]))\n",
    "        if max_likelihood is None or likelihood > max_likelihood:\n",
    "            max_likelihood = likelihood\n",
    "            best_fit = (alpha, beta, mu)\n",
    "    return best_fit, max_likelihood\n",
    "\n",
    "\n",
    "def probability_of_lottery_choice_LUCE(alpha, beta, mu, lottery_value, certain_value, ambiguity, probability):\n",
    "    SV_lottery, SV_certain = SVs(alpha, beta, lottery_value, certain_value, ambiguity, probability)\n",
    "    p = np.sign(SV_lottery) * np.abs(SV_lottery)**(1 / mu) / (np.sign(SV_lottery) * np.abs(SV_lottery)**(1 / mu) + np.sign(SV_certain) * np.abs(SV_certain)**(1 / mu))\n",
    "    idx = np.where(SV_lottery < 0)[0]\n",
    "    p[idx] = 1 - p[idx]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_proj_dir = os.path.join(base_proj_dir, \"derivatives/adult/parameter_estimation/luce\")\n",
    "\n",
    "subs = [] \n",
    "descriptives = {}\n",
    "\n",
    "for i in [\"gain\", \"loss\", \"combined\"]:\n",
    "        for j in [\"resp_rate\", \"prop_lott_risk\", \"prop_lott_amb\", \"prop_lott_all\",\n",
    "                    \"conf1_ct\", \"conf2_ct\", \"conf3_ct\", \"conf4_ct\", \"conf_mean\", \"at_bound\"]:\n",
    "            descriptives[\"{0}_{1}\".format(j, i)] = []\n",
    "\n",
    "df_participants = pd.DataFrame(columns = [\"SubID\", \"Session\", \"Domain\",\n",
    "                                            \"Alpha\", \"Beta\", \"Mu\", \n",
    "                                            \"MaxLL\", \"R2\", \"AIC\", \"AIC0\"]) \n",
    "\n",
    "files = sorted(glob(os.path.join(data_dir, \"*.csv\")))\n",
    "for curr_file in files:\n",
    "    sub_id = os.path.basename(curr_file)[:5]\n",
    "    if not sub_id in subs:\n",
    "        subs.append(sub_id)\n",
    "\n",
    "for idx, sub in enumerate(subs):\n",
    "    save_sub_dir = os.path.join(save_proj_dir, \"sub-{0}\".format(sub))\n",
    "    if not os.path.exists(save_sub_dir):\n",
    "        os.makedirs(save_sub_dir)\n",
    "    sub_files = sorted(glob(os.path.join(data_dir, \"{0}*_crdm.csv\".format(sub))))\n",
    "    sub_cols = [\"domain\", \"prob\", \"amb\", \"sure_amt\", \"lott_amt\", \"choice\"]\n",
    "    sub_df = pd.DataFrame(columns = sub_cols)\n",
    "    if len(sub_files) == 1:\n",
    "        continue\n",
    "    else:\n",
    "        for i in range(1, -1, -1):\n",
    "            raw_df = pd.read_csv(sub_files[i])\n",
    "            df = raw_df.loc[(raw_df[\"crdm_trial_type\"] == \"task\") & (raw_df[\"crdm_choice\"].notnull())]\n",
    "            sub_df[\"domain\"] = df[\"crdm_domain\"]\n",
    "            sub_df[\"prob\"] = df[\"crdm_lott_p\"]\n",
    "            sub_df[\"amb\"] = df[\"crdm_amb_lev\"]\n",
    "            sub_df[\"sure_amt\"] = df[\"crdm_sure_amt\"]\n",
    "            sub_df[\"lott_amt\"] = df[\"crdm_lott_top\"] + df[\"crdm_lott_bot\"]\n",
    "            sub_df[\"choice\"] = df[\"crdm_choice\"]\n",
    "            sub_gains = sub_df.loc[(sub_df[\"domain\"] == \"gain\")]\n",
    "            sub_losses = sub_df.loc[(sub_df[\"domain\"] == \"loss\")]\n",
    "            df_dict = {\"gain\": sub_gains, \"loss\": sub_losses, \"combined\": sub_df}\n",
    "            if i == 1:\n",
    "                gf_alpha, gf_beta, gf_mu, df_participants = fit_data_LUCE(sub_gains,  \"S1\", \"gain\", sub, df_participants)\n",
    "                lf_alpha, lf_beta, lf_mu, df_participants = fit_data_LUCE(sub_losses, \"S1\", \"loss\", sub, df_participants)\n",
    "                cf_alpha, cf_beta, cf_mu, df_participants = fit_data_LUCE(sub_df,     \"S1\", \"both\", sub, df_participants)\n",
    "                for d in [\"gain\", \"loss\", \"combined\"]:\n",
    "                    if d == \"combined\":\n",
    "                        descriptives[\"resp_rate_combined\"].append(len(df_dict[d][\"choice\"]) / len(raw_df.loc[(raw_df[\"crdm_trial_type\"] == \"task\")]))\n",
    "                    else:\n",
    "                        descriptives[\"resp_rate_{0}\".format(d)].append(len(df_dict[d][\"choice\"]) / len(raw_df.loc[(raw_df[\"crdm_domain\"] == \"{0}\".format(d)) \n",
    "                                                                                                                    & (raw_df[\"crdm_trial_type\"] == \"task\")]))\n",
    "                    descriptives[\"prop_lott_risk_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"amb\"] == 0) \n",
    "                                                                        & (df_dict[d][\"choice\"] == 1)]) / len((df_dict[d][\"amb\"] == 0)))\n",
    "                    descriptives[\"prop_lott_amb_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"amb\"] != 0) \n",
    "                                                                        & (df_dict[d][\"choice\"] == 1)]) / len((df_dict[d][\"amb\"] != 0)))\n",
    "                    descriptives[\"prop_lott_all_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"choice\"] == 1)]) / len(df_dict[d][\"choice\"]))\n",
    "                    descriptives[\"conf1_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 1)]))\n",
    "                    descriptives[\"conf2_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 2)]))\n",
    "                    descriptives[\"conf3_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 3)]))\n",
    "                    descriptives[\"conf4_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 4)]))\n",
    "                    descriptives[\"conf_mean_{0}\".format(d)].append(np.nanmean(df[\"crdm_conf_resp.keys\"]))\n",
    "                    if gf_alpha <= 0.11 or gf_alpha >= 1.99 or gf_beta <= -1.29 or gf_beta >= 1.29 or gf_mu <= 0.01 or gf_mu >= 7.99:\n",
    "                        descriptives[\"at_bound_{0}\".format(d)].append(1)\n",
    "                    else:\n",
    "                        descriptives[\"at_bound_{0}\".format(d)].append(0)\n",
    "            else:\n",
    "                gf_alpha, gf_beta, gf_mu, df_participants = fit_data_LUCE(sub_gains,  \"S2\", \"gain\", sub, df_participants)\n",
    "                lf_alpha, lf_beta, lf_mu, df_participants = fit_data_LUCE(sub_losses, \"S2\", \"loss\", sub, df_participants)  \n",
    "                cf_alpha, cf_beta, cf_mu, df_participants = fit_data_LUCE(sub_df,     \"S2\", \"both\", sub, df_participants) \n",
    "                for d in [\"gain\", \"loss\", \"combined\"]:\n",
    "                    if d == \"combined\":\n",
    "                        descriptives[\"resp_rate_combined\"].append(len(df_dict[d][\"choice\"]) / len(raw_df.loc[(raw_df[\"crdm_trial_type\"] == \"task\")]))\n",
    "                    else:\n",
    "                        descriptives[\"resp_rate_{0}\".format(d)].append(len(df_dict[d][\"choice\"]) / len(raw_df.loc[(raw_df[\"crdm_domain\"] == \"{0}\".format(d)) \n",
    "                                                                                                                    & (raw_df[\"crdm_trial_type\"] == \"task\")]))\n",
    "                    descriptives[\"prop_lott_risk_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"amb\"] == 0) \n",
    "                                                                        & (df_dict[d][\"choice\"] == 1)]) / len((df_dict[d][\"amb\"] == 0)))\n",
    "                    descriptives[\"prop_lott_amb_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"amb\"] != 0) \n",
    "                                                                        & (df_dict[d][\"choice\"] == 1)]) / len((df_dict[d][\"amb\"] != 0)))\n",
    "                    descriptives[\"prop_lott_all_{0}\".format(d)].append(len(df_dict[d].loc[(df_dict[d][\"choice\"] == 1)]) / len(df_dict[d][\"choice\"]))\n",
    "                    descriptives[\"conf1_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 1)]))\n",
    "                    descriptives[\"conf2_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 2)]))\n",
    "                    descriptives[\"conf3_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 3)]))\n",
    "                    descriptives[\"conf4_ct_{0}\".format(d)].append(len(df.loc[(df[\"crdm_conf_resp.keys\"] == 4)]))\n",
    "                    descriptives[\"conf_mean_{0}\".format(d)].append(np.nanmean(df[\"crdm_conf_resp.keys\"]))\n",
    "                    if gf_alpha <= 0.11 or gf_alpha >= 1.99 or gf_beta <= -1.29 or gf_beta >= 1.29 or gf_mu <= 0.01 or gf_mu >= 7.99:\n",
    "                        descriptives[\"at_bound_{0}\".format(d)].append(1) \n",
    "                    else:\n",
    "                        descriptives[\"at_bound_{0}\".format(d)].append(0)\n",
    "            print(sub, end = \"\\r\")\n",
    "\n",
    "idxG = np.where(df_participants[\"Domain\"].values == \"gain\")[0]\n",
    "idxL = np.where(df_participants[\"Domain\"].values == \"loss\")[0]\n",
    "idxC = np.where(df_participants[\"Domain\"].values == \"both\")[0]\n",
    "stacked_data = np.hstack((df_participants.values[idxG], df_participants.values[idxL], df_participants.values[idxC])) \n",
    "temp_df = pd.DataFrame(stacked_data, columns = [\"PID\", \"Session\", \n",
    "                                                \"d1\",\n",
    "                                                \"Alpha-G\", \"Beta-G\", \"Mu-G\", \"MLL-G\", \"R2-G\", \"AIC-G\", \"AIC0-G\", \n",
    "                                                \"d2\", \"d3\", \"d4\", \n",
    "                                                \"Alpha-L\", \"Beta-L\", \"Mu-L\", \"MLL-L\", \"R2-L\", \"AIC-L\", \"AIC0-L\",\n",
    "                                                \"d5\", \"d6\", \"d7\",\n",
    "                                                \"Alpha-C\", \"Beta-C\", \"Mu-C\", \"MLL-C\", \"R2-C\", \"AIC-C\", \"AIC0-C\"])\n",
    "df_participants = temp_df.drop([\"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\"], axis = 1) \n",
    "\n",
    "dom = [\"G\", \"L\", \"C\"]\n",
    "for i, d in enumerate([\"gain\", \"loss\", \"combined\"]):\n",
    "    df_participants[\"RespRate-{0}\".format(dom[i])] = np.round(descriptives[\"resp_rate_{0}\".format(d)], 2)\n",
    "    df_participants[\"RiskLottC-{0}\".format(dom[i])] = np.round(descriptives[\"prop_lott_risk_{0}\".format(d)], 2)\n",
    "    df_participants[\"AmbigLottC-{0}\".format(dom[i])] = np.round(descriptives[\"prop_lott_amb_{0}\".format(d)], 2)\n",
    "    df_participants[\"AllLottC-{0}\".format(dom[i])] = np.round(descriptives[\"prop_lott_all_{0}\".format(d)], 2)\n",
    "    df_participants[\"Conf1-{0}\".format(dom[i])] = descriptives[\"conf1_ct_{0}\".format(d)]\n",
    "    df_participants[\"Conf2-{0}\".format(dom[i])] = descriptives[\"conf2_ct_{0}\".format(d)]\n",
    "    df_participants[\"Conf3-{0}\".format(dom[i])] = descriptives[\"conf3_ct_{0}\".format(d)]\n",
    "    df_participants[\"Conf4-{0}\".format(dom[i])] = descriptives[\"conf4_ct_{0}\".format(d)]\n",
    "    df_participants[\"ConfAvg-{0}\".format(dom[i])] = np.round(descriptives[\"conf_mean_{0}\".format(d)], 2)\n",
    "    df_participants[\"ParamOut-{0}\".format(dom[i])] = descriptives[\"at_bound_{0}\".format(d)]\n",
    "\n",
    "filename = os.path.join(save_proj_dir, \"sdan-crdm-luce_modelfitGL.csv\")\n",
    "df_participants.to_csv(filename, columns = [\"PID\", \"Session\", \"Alpha-G\", \"Beta-G\", \"Mu-G\", \"MLL-G\", \"R2-G\", \n",
    "                                            \"AIC-G\", \"AIC0-G\", \"RespRate-G\", \"RiskLottC-G\", \"AmbigLottC-G\", \"AllLottC-G\", \n",
    "                                            \"Conf1-G\", \"Conf2-G\", \"Conf3-G\", \"Conf4-G\", \"ConfAvg-G\", \"ParamOut-G\",\n",
    "                                            \"Alpha-L\", \"Beta-L\", \"Mu-L\", \"MLL-L\", \"R2-L\", \n",
    "                                            \"AIC-L\", \"AIC0-L\", \"RespRate-L\", \"RiskLottC-L\", \"AmbigLottC-L\", \"AllLottC-L\", \n",
    "                                            \"Conf1-L\", \"Conf2-L\", \"Conf3-L\", \"Conf4-L\", \"ConfAvg-L\", \"ParamOut-L\",\n",
    "                                            \"Alpha-C\", \"Beta-C\", \"Mu-C\", \"MLL-C\", \"R2-C\", \n",
    "                                            \"AIC-C\", \"AIC0-C\", \"RespRate-C\", \"RiskLottC-C\", \"AmbigLottC-C\", \"AllLottC-C\", \n",
    "                                            \"Conf1-C\", \"Conf2-C\", \"Conf3-C\", \"Conf4-C\", \"ConfAvg-C\", \"ParamOut-C\"],\n",
    "                                            index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_participants"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
