{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RIC1-CPDM Descriptives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: \n",
    "* CPDM behavioral file from Psychopy [sub-####_ses-cpdm_task.csv]\n",
    "\n",
    "Ouput: \n",
    "* CRDM CSV file [sub-####_ses-cpdm.csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "analysis = \"1\"\n",
    "base_proj_dir = \"Z:/data/RIC/\" ## base project directory\n",
    "data_dir = \"Z:/data/RIC/sourcedata/RIC{0}/\".format(analysis) ## directory containing data\n",
    "save_proj_dir = os.path.join(base_proj_dir, \"derivatives/RIC{0}/descriptives/cpdm\".format(analysis)) ## output directory\n",
    "if not os.path.exists(save_proj_dir): ## new Ss\n",
    "    os.makedirs(save_proj_dir) ## make new Ss save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives = {\"SubID\":[]}\n",
    "dict_keys    = [\"RespRate\", \"Acc\", \"HighConfProp\", \"LowConfProp\", \n",
    "                \"HighConfCt\", \"LowConfCt\", \"ConfAvg\"]\n",
    "tags = [\"ALL\", \"LVLR\", \"LVHR\", \"HVLR\", \"HVHR\"] ## unique per analysis\n",
    "runs = [\"all_runs\", \n",
    "        \"low_vol_low_risk\", \"low_vol_high_risk\", \n",
    "        \"high_vol_low_risk\", \"high_vol_high_risk\"] ## unique per analysis\n",
    "\n",
    "for tag in tags:\n",
    "    for label in dict_keys:\n",
    "        descriptives[\"{0} {1}\".format(tag, label)] = [] ## create dict keys/empty lists\n",
    "\n",
    "sub_files = sorted(glob(os.path.join(data_dir, \"23_IDM_*.csv\"))) ## grab all CRDM task csvs files in folder\n",
    "for i, curr_file in enumerate(sub_files): ## go through each subject file\n",
    "    sub_id = os.path.basename(curr_file)[7:11] ## grab first 5 indices of filename string\n",
    "    if not sub_id in descriptives[\"SubID\"]: ## check if already in list\n",
    "        descriptives[\"SubID\"].append(os.path.basename(curr_file)[7:11]) ## append current subject ID to subs list\n",
    "\n",
    "for idx, sub in enumerate(descriptives[\"SubID\"]): ## iterate through Ss ID list\n",
    "    sub_file = sorted(glob(os.path.join(data_dir, \"23_IDM_{0}.csv\".format(sub)))) ## grab Ss task csv\n",
    "    sub_cols = [\"run\", \"acc\", \"conf\", \"money\", \"choice\"] ## trial variables\n",
    "    sub_df   = pd.DataFrame(columns = sub_cols) ## new subject-specific dataframe w/ preset columns\n",
    "    raw_df   = pd.read_csv(sub_file[0]) ## open current data file\n",
    "    df       = raw_df.loc[(raw_df[\"cpdm_trial_type\"] == \"task\") & (raw_df[\"cpdm_trial_resp.keys\"].notnull())] ## CPDM task response trials only\n",
    "    sub_df[\"run\"]    = df[\"cpdm_run_dimension\"] ## don't *need* a new df, just makes things simpler\n",
    "    sub_df[\"acc\"]    = df[\"cpdm_acc\"]\n",
    "    sub_df[\"conf\"]   = df[\"cpdm_conf\"]\n",
    "    sub_df[\"money\"]  = df[\"cpdm_money\"]\n",
    "    choice_dict      = {'q':-2, 'a':-1, 'l':1, 'p':2} ## remap choice responses to match CASANDRE conceptualization\n",
    "    sub_df[\"choice\"] = df[\"cpdm_trial_resp.keys\"].replace(choice_dict) ## replace old choices with remapped values\n",
    "    for j, run_type in enumerate(runs):\n",
    "        run_df = pd.DataFrame() ## empty run df\n",
    "        if run_type == \"all_runs\":\n",
    "            run_df = sub_df ## excludes nonresp trials\n",
    "            descriptives[\"ALL RespRate\"].append(np.round(len(run_df[\"choice\"]) / \n",
    "                                                            len(raw_df.loc[(raw_df[\"cpdm_trial_type\"] == \"task\")]), 3))\n",
    "        else:\n",
    "            run_df = sub_df.loc[(sub_df[\"run\"] == run_type)]\n",
    "            descriptives[\"{0} RespRate\".format(tags[j])].append(np.round(len(run_df[\"choice\"]) / \n",
    "                                                                        len(raw_df.loc[(raw_df[\"cpdm_trial_type\"] == \"task\") \n",
    "                                                                                        & (raw_df[\"cpdm_run_dimension\"] == run_type)]), 3))\n",
    "        descriptives[\"{0} Acc\".format(tags[j])].append(np.round(sum(run_df[\"acc\"]) / len(run_df[\"acc\"]), 3))\n",
    "        descriptives[\"{0} HighConfProp\".format(tags[j])].append(np.round(sum(run_df[\"conf\"]) / len(run_df[\"conf\"]), 3))\n",
    "        descriptives[\"{0} LowConfProp\".format(tags[j])].append(np.round(1 - (sum(run_df[\"conf\"]) / len(run_df[\"conf\"])), 3))\n",
    "        descriptives[\"{0} HighConfCt\".format(tags[j])].append(sum(run_df[\"conf\"]))\n",
    "        descriptives[\"{0} LowConfCt\".format(tags[j])].append(len(run_df[\"conf\"]) - sum(run_df[\"conf\"]))\n",
    "        descriptives[\"{0} ConfAvg\".format(tags[j])].append(np.round(np.mean(run_df[\"conf\"]), 3))\n",
    "descriptives_df = pd.DataFrame(descriptives)\n",
    "descriptives_df[\"SubID\"] = descriptives_df[\"SubID\"].apply('=\"{}\"'.format) ## keeps zeros padding for SubID using string format\n",
    "filename = os.path.join(save_proj_dir, \"ric{0}-cpdm-descriptives.csv\".fomat(analysis))\n",
    "descriptives_df.to_csv(filename, index = False) ## save csv without dataframe row indexing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
