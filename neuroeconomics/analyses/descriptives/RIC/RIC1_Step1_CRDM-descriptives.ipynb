{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RIC1-CRDM Descriptives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: \n",
    "* CRDM behavioral file from Psychopy [sub-####_ses-crdm_task.csv]\n",
    "\n",
    "Ouput: \n",
    "* CRDM CSV file [sub-####_ses-crdm.csv]\n",
    "* CRDM Choice Plots [sub-####_ses-crdm_choice-plots.png]\n",
    "* CRDM Risk Figures [sub-####_ses-crdm_risk-trials.png]\n",
    "* CRDM Ambiguity Trial Figures [sub-####_ses-crdm_amb-trials.png]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_theme(style = \"white\", palette = \"muted\")\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = \"1\"\n",
    "base_proj_dir = \"Z:/data/RIC\" ## base project directory\n",
    "data_dir = \"Z:/data/RIC/sourcedata/RIC1{0}\".format(analysis) ## directory containing data\n",
    "\n",
    "\n",
    "subs        = []\n",
    "amb_levels  =  [0, 24, 50, 74]\n",
    "prob_levels =  [13, 25, 38, 50, 75]\n",
    "prob_counts =  {\"13p_0a_safe\":[], \"13p_0a_lott\":[], \"13p_0a_nr\":[],\n",
    "                \"25p_0a_safe\":[], \"25p_0a_lott\":[], \"25p_0a_nr\":[],\n",
    "                \"38p_0a_safe\":[], \"38p_0a_lott\":[], \"38p_0a_nr\":[],\n",
    "                \"50p_0a_safe\":[], \"50p_0a_lott\":[], \"50p_0a_nr\":[],\n",
    "                \"75p_0a_safe\":[], \"75p_0a_lott\":[], \"75p_0a_nr\":[]}\n",
    "amb_counts  =  {\"50p_0a_safe\":[],  \"50p_0a_lott\":[],  \"50p_0a_nr\":[],\n",
    "                \"50p_24a_safe\":[], \"50p_24a_lott\":[], \"50p_24a_nr\":[],\n",
    "                \"50p_50a_safe\":[], \"50p_50a_lott\":[], \"50p_50a_nr\":[],\n",
    "                \"50p_74a_safe\":[], \"50p_74a_lott\":[], \"50p_74a_nr\":[]} ## across subjects counts for ambiguity trials\n",
    "\n",
    "sub_files = sorted(glob(os.path.join(data_dir, \"23_IDM_*.csv\"))) ## grab all CRDM task csvs files in folder\n",
    "for i, curr_file in enumerate(sub_files): ## go through each subject file\n",
    "    subs.append(os.path.basename(curr_file)[7:11]) ## append current subject ID to subs list\n",
    "    sub_cols = [\"prob\", \"amb\", \"sure_amt\", \"lott_amt\", \"choice\"] ## trial variables to be saved to output file\n",
    "    sub_df = pd.DataFrame(columns = sub_cols) ## subject-specific dataframe   \n",
    "    raw_df = pd.read_csv(curr_file) ## import Ss behav file into Panda's dataframepd.read_csv(curr_file) #import Ss behav file into Panda's dataframe\n",
    "    resp_df = raw_df.loc[(raw_df[\"crdm_trial_type\"] == \"task\") & (raw_df[\"crdm_choice\"].notnull())] ## only task trials with responses\n",
    "    nonresp_df = raw_df.loc[(raw_df[\"crdm_trial_type\"] == \"task\") & (raw_df[\"crdm_choice\"].isnull())] ## only task trials with nonresponses (important for creating EV file)\n",
    "\n",
    "    for k, this_prob in enumerate(prob_levels):\n",
    "        for l, this_choice in enumerate([\"safe\", \"lott\"]):\n",
    "            prob_counts[\"{0}p_0a_{1}\".format(this_prob, this_choice)].append(len(resp_df.loc[(resp_df[\"crdm_lott_p\"] == this_prob) \n",
    "                                                                                            & (resp_df[\"crdm_amb_lev\"] == 0) \n",
    "                                                                                            & (resp_df[\"crdm_choice\"] == l)]))\n",
    "        prob_counts[\"{0}p_0a_nr\".format(this_prob)].append(len(nonresp_df.loc[(nonresp_df[\"crdm_lott_p\"] == this_prob) \n",
    "                                                                            & (nonresp_df[\"crdm_amb_lev\"] == 0)]))\n",
    "    for k, this_amb in enumerate(amb_levels): ## calculates and saves ambiguity trial count info for response and nonresponse trials\n",
    "        for l, this_choice in enumerate([\"safe\", \"lott\"]):\n",
    "            amb_counts[\"50p_{0}a_{1}\".format(this_amb, this_choice)].append(len(resp_df.loc[(resp_df[\"crdm_lott_p\"] == 50)\n",
    "                                                                                            & (resp_df[\"crdm_amb_lev\"] == this_amb) \n",
    "                                                                                            & (resp_df[\"crdm_choice\"] == l)]))\n",
    "        amb_counts[\"50p_{0}a_nr\".format(this_amb)].append(len(nonresp_df.loc[(nonresp_df[\"crdm_lott_p\"] == 50) \n",
    "                                                                            & (nonresp_df[\"crdm_amb_lev\"] == this_amb)]))\n",
    "    temp_df = pd.DataFrame() ## create fresh DF for each pain lev/prob combo\n",
    "    temp_df['prob'] = resp_df['crdm_lott_p'] ## trial probability\n",
    "    temp_df['amb'] = resp_df['crdm_amb_lev'] ## trial ambiguity\n",
    "    temp_df['sure_amt'] = resp_df['crdm_sure_amt'] ## trial certain amount\n",
    "    temp_df['lott_amt'] = resp_df['crdm_lott_top'] + resp_df['crdm_lott_bot'] ## trial lottery amount\n",
    "    temp_df['choice'] = resp_df['crdm_choice'] ## trial choice (-1 = nonresponse, 0 = certain, 1 = lottery)\n",
    "    temp_df = temp_df.astype(int) ## convert elements of dataframe to integers\n",
    "\n",
    "    temp_df2 = pd.DataFrame() ## create separate DF for nonresponse task trials\n",
    "    temp_df2[\"prob\"] = nonresp_df[\"crdm_lott_p\"] ## lottery probability\n",
    "    temp_df2[\"amb\"] = nonresp_df[\"crdm_amb_lev\"] ## lottery ambiguity\n",
    "    temp_df2[\"sure_amt\"] = nonresp_df[\"crdm_sure_amt\"] ## certain $ amount\n",
    "    temp_df2[\"lott_amt\"] = nonresp_df[\"crdm_lott_top\"] + nonresp_df[\"crdm_lott_bot\"] ## winning lottery amount\n",
    "    temp_df2[\"choice\"] = [-1] * len(temp_df2[\"sure_amt\"]) ## trial choice [all -1 to indicate nonresponse]\n",
    "    temp_df2 = temp_df2.astype(int) ## convert all elements of dataframe to integers\n",
    "\n",
    "\n",
    "    ##### PROBABILITY TRIALS #####\n",
    "    fig1 = plt.figure(i, figsize = (14, 8)) ## create Ss figure\n",
    "    for prob_idx, curr_prob in enumerate(prob_levels): ## 5 probability levels\n",
    "        prob_loc = 1 + prob_idx ## index for sub-plot location\n",
    "        fig1.add_subplot(2, 5, prob_loc) ## defining location of subfigure\n",
    "        ## probability specific dataframe (individual trials)\n",
    "        curr_trials1 = temp_df.loc[(temp_df[\"prob\"] == curr_prob) & (temp_df[\"amb\"] == 0)] ## grab trials for current probability level\n",
    "        sub_df = pd.concat([sub_df, curr_trials1], ignore_index=True) ## add to subject output file dataframe\n",
    "        ## isolation of unique lottery/choice pairs \n",
    "        all_x = curr_trials1[\"lott_amt\"].tolist() ## convert all lottery amounts series to list\n",
    "        all_y = curr_trials1[\"choice\"].tolist() ## convert all choices series to list\n",
    "        amt_choice_combos = list(zip(all_x, all_y)) ## tuples of lottery/choices for all relevant trials\n",
    "        unique_combos = sorted(list(set(amt_choice_combos))) ## only unique lottery/choice combos\n",
    "        #combo_ct = [amt_choice_combos.count(item) for item in unique_combos] ## number of trials for each element of unique_combos\n",
    "        x, y = list(zip(*sorted(unique_combos))) ## unzip unique_combos\n",
    "        x2 = []\n",
    "        for curr_x in x: ## add $ to x-axis values\n",
    "            x2.append(\"$\"+str(curr_x))\n",
    "        plt.plot(x2, y, 'ro-') ## red = risk trials\n",
    "        plt.ylim([-0.05, 1.05]) ## buffer extremes of y-axis\n",
    "        sns.despine(top = True) ## remove ticks and upper/right sides of subplots\n",
    "        if prob_idx == 0: ## only add y axis labels to far left subfigures (row)\n",
    "            plt.yticks([0, 1], [\"Certain (0)\", \"Lottery (1)\"])\n",
    "            plt.ylabel(\"Probability of Lottery Choice\")\n",
    "        else:\n",
    "            plt.yticks([])\n",
    "        plt.title(str(curr_prob) + \"% Prob - 0% Amb\", fontsize = 12, color = \"red\") ## title for each probability subplot\n",
    "\n",
    "\n",
    "    ##### AMBIGUITY TRIALS #####\n",
    "    for amb_idx, curr_amb in enumerate(amb_levels):\n",
    "        amb_loc = 5 + amb_idx\n",
    "        fig1.add_subplot(2, 4, amb_loc)\n",
    "        curr_trials2 = temp_df.loc[(temp_df[\"prob\"] == 50) & (temp_df[\"amb\"] == curr_amb)] \n",
    "        all_x = curr_trials2[\"lott_amt\"].tolist() \n",
    "        all_y = curr_trials2[\"choice\"].tolist() \n",
    "        amt_choice_combos = list(zip(all_x, all_y)) \n",
    "        unique_combos = list(set(amt_choice_combos)) \n",
    "        #combo_ct = [amt_choice_combos.count(item) for item in unique_combos] \n",
    "        x, y = list(zip(*sorted(unique_combos)))\n",
    "        x2 = []\n",
    "        for curr_x in x:\n",
    "            x2.append(\"$\"+str(curr_x))\n",
    "        curr_trials3 = curr_trials2.loc[(curr_trials2[\"amb\"] != 0)] ## used specifically to prevent duplication in output csv\n",
    "        sub_df = pd.concat([sub_df, curr_trials3], ignore_index=True) ## add to Ss csv dataframe\n",
    "        plt.plot(x2, y, 'bo-') ## blue = ambiguity trials\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        sns.despine(top=True)\n",
    "        if amb_idx == 0:\n",
    "            plt.yticks([0, 1], [\"Certain (0)\", \"Lottery (1)\"])\n",
    "            plt.ylabel(\"Probability of Lottery Choice\")\n",
    "        else:\n",
    "            plt.yticks([])\n",
    "        plt.xlabel(\"Lottery Value\")\n",
    "        plt.title(\"50% Prob - {0}% Amb\".format(str(curr_amb)), fontsize = 12, color = \"blue\")\n",
    "    ## Complete plot\n",
    "    plt.suptitle(\"RIC{0} sub-{1}\".format(analysis, subs[i]), fontsize = 18) \n",
    "    save_sub_dir = os.path.join(base_proj_dir, \"derivatives/RIC{0}/descriptives/crdm/sub-{1}\".format(analysis, subs[i])) ## set Ss specific save directory\n",
    "    if not os.path.exists(save_sub_dir): ## new Ss\n",
    "        os.makedirs(save_sub_dir) ## make new Ss save directory\n",
    "        print(\"---------------> NEW PARTICIPANT DIRECTORY CREATED: sub-{0}\".format(subs[i])) ## indicate new Ss directory was made\n",
    "    fig_save = os.path.join(save_sub_dir, \"sub-{0}_ric{1}-crdm_choice-plots.png\".format(subs[i]), analysis) \n",
    "    print(\"Saving to: {0}\".format(fig_save)) \n",
    "    plt.savefig(fig_save) \n",
    "    #plt.show() \n",
    "    sub_filename = os.path.join(save_sub_dir, \"sub-{0}_ric{1}-crdm_choice-behavior.csv\".format(subs[i]), analysis) ## path/filename to save csv\n",
    "    print(\"Saving to: {0}\".format(sub_filename)) ## indicate Ss save directory\n",
    "    sub_df.to_csv(sub_filename, index = False) ## save output file\n",
    "\n",
    "prob_counts_df = pd.DataFrame(prob_counts, index = subs) ## convert prob_counts dict to DF\n",
    "amb_counts_df = pd.DataFrame(amb_counts, index = subs) ## convert amb_counts dict to DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice Counts & Percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risky Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, curr_sub in enumerate(subs):\n",
    "    risk_count =   {\"13p_safe\":[], \"13p_lott\":[], \"13p_nr\":[],\n",
    "                    \"25p_safe\":[], \"25p_lott\":[], \"25p_nr\":[],\n",
    "                    \"38p_safe\":[], \"38p_lott\":[], \"38p_nr\":[],\n",
    "                    \"50p_safe\":[], \"50p_lott\":[], \"50p_nr\":[],\n",
    "                    \"75p_safe\":[], \"75p_lott\":[], \"75p_nr\":[]}\n",
    "    risk_prop = {\"13p_lott\":[], \"25p_lott\":[], \"38p_lott\":[], \"50p_lott\":[], \"75p_lott\":[]}\n",
    "    for x in [\"13\", \"25\", \"38\", \"50\", \"75\"]:\n",
    "        for y in [\"safe\", \"lott\", \"nr\"]:\n",
    "            risk_count[\"{0}p_{1}\".format(x, y)].append(prob_counts_df[\"{0}p_0a_{1}\".format(x, y)][idx]) \n",
    "        risk_prop[\"{0}p_lott\".format(x)].append(prob_counts_df[\"{0}p_0a_lott\".format(x)][idx] / (prob_counts_df[\"{0}p_0a_lott\".format(x)][idx]\n",
    "                                                                                                + prob_counts_df[\"{0}p_0a_safe\".format(x)][idx] \n",
    "                                                                                                + prob_counts_df[\"{0}p_0a_nr\".format(x)][idx]))        \n",
    "    risk_count_df = pd.DataFrame(risk_count) ## convert dicts to DFs\n",
    "    risk_prop_df = pd.DataFrame(risk_prop)\n",
    "\n",
    "    figure, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
    "    sns.despine(top = True)\n",
    "    sns.barplot(risk_count_df, ax = axes[0])\n",
    "    sns.barplot(risk_prop_df, ax = axes[1])\n",
    "    axes[0].set_ylabel(\"Number of Trials\")\n",
    "    axes[0].set_xlabel(\"Lottery Probability/Response\")\n",
    "    axes[0].set_yticklabels(axes[0].get_yticks().astype(int))\n",
    "    axes[0].bar_label(axes[0].containers[0])\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].set_ylabel(\"Proportion of Trials\")\n",
    "    axes[1].bar_label(axes[1].containers[0])\n",
    "    axes[1].set_xlabel(\"Lottery Probability\")\n",
    "    plt.suptitle(\"RIC2 sub-{0} - Risk Trial Descriptives\".format(subs[idx], fontsize = 20)) \n",
    "    save_sub_dir = os.path.join(base_proj_dir, \"derivatives/RIC{0}/descriptives/crdm/sub-{1}\".format(analysis, subs[idx]))\n",
    "    fig_save = os.path.join(save_sub_dir, \"sub-{0}_ric{1}-crdm_trials-risk.png\".format(subs[idx], analysis)) \n",
    "    plt.savefig(fig_save)\n",
    "    print(\"Saving to: {0}\".format(fig_save)) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiguity Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, curr_sub in enumerate(subs):\n",
    "    amb_count = {\"24a_safe\":[], \"24a_lott\":[], \"24a_nr\":[],\n",
    "                \"50a_safe\":[], \"50a_lott\":[], \"50a_nr\":[],\n",
    "                \"74a_safe\":[], \"74a_lott\":[], \"74a_nr\":[]}\n",
    "    amb_prop = {\"24a_lott\":[], \"50a_lott\":[], \"74a_lott\":[],}\n",
    "    for x in [\"24\", \"50\", \"74\"]:\n",
    "        for y in [\"safe\", \"lott\", \"nr\"]:\n",
    "            amb_count[\"{0}a_{1}\".format(x, y)].append(amb_counts_df[\"50p_{0}a_{1}\".format(x, y)][idx]) \n",
    "        amb_prop[\"{0}a_lott\".format(x)].append(amb_counts_df[\"50p_{0}a_lott\".format(x)][idx] / (amb_counts_df[\"50p_{0}a_lott\".format(x)][idx]\n",
    "                                                                                                + amb_counts_df[\"50p_{0}a_safe\".format(x)][idx] \n",
    "                                                                                                + amb_counts_df[\"50p_{0}a_nr\".format(x)][idx]))        \n",
    "    amb_count_df = pd.DataFrame(amb_count)\n",
    "    amb_prop_df = pd.DataFrame(amb_prop)\n",
    "\n",
    "    figure, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
    "    \n",
    "    sns.barplot(amb_count_df, ax = axes[0])\n",
    "    sns.despine(top = True)\n",
    "    axes[0].set_ylabel(\"Number of Trials\")\n",
    "    axes[0].set_xlabel(\"Lottery Probability/Response\")\n",
    "    axes[0].set_yticklabels(axes[0].get_yticks().astype(int))\n",
    "    axes[0].bar_label(axes[0].containers[0])\n",
    "\n",
    "    sns.barplot(amb_prop_df, ax = axes[1])\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].set_ylabel(\"Proportion of Trials\")\n",
    "    axes[1].bar_label(axes[1].containers[0])\n",
    "    axes[1].set_xlabel(\"Lottery Probability\")\n",
    "    plt.suptitle(\"RIC2 sub-{0} - Ambiguity Trial Descriptives\".format(subs[idx], fontsize = 20)) \n",
    "    save_sub_dir = os.path.join(base_proj_dir, \"derivatives/RIC{0}/descriptives/crdm/sub-{1}\".format(analysis, subs[idx]))\n",
    "    fig_save = os.path.join(save_sub_dir, \"sub-{0}_ric{1}-crdm_trials-amb.png\".format(subs[idx], analysis)) \n",
    "    plt.savefig(fig_save)\n",
    "    print(\"Saving to: {0}\".format(fig_save)) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use to remove files if I decide to change naming convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, curr_sub in enumerate(subs):\n",
    "    remove_dir = os.path.join(base_proj_dir, \"derivatives/RIC{0}/descriptives/crdm/sub-{1}\".format(analysis, subs[idx]))\n",
    "    fig_remove = os.path.join(remove_dir, \"sub-{0}_ric{1}-crdm_amb-trials.png\".format(subs[idx], analysis))       \n",
    "    #os.remove(fig_remove) ## uncomment only if you're **VERY** sure you want to delete something...\n",
    "    print(curr_sub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
