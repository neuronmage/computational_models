{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CRDM Beta Simulation (CCB Project): Version 2**\n",
    "\n",
    "#### Softmax Choice Model *only*\n",
    "- Alpha [0.3, 1.2, 0.05] vs alpha constant [0.6]\n",
    "    - While I realize the possible Alpha bounds swere [0.13, 4.68], iterating through this range with any fidelity would result in an unreasonable number of simulated Ss\n",
    "    - So I narrowed the alpha range based on my experience with the value at which alpha began to fall apart with ADO\n",
    "- Beta [-4.16, 4.16, 8.34/500], obtaining 500 steps (*simulated subjects*)\n",
    "- Gamma constant [1.5]\n",
    "\n",
    "##### **Version 2 Improvements** Restructures data into numpy arrays to improve computational efficiency (hrs --> secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===================\n",
    "Mandy Renfro (2024)\n",
    "===================\n",
    "\"\"\"\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.seterr(all = \"ignore\")\n",
    "import os\n",
    "import os.path, sys\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style = \"white\", palette = \"muted\")\n",
    "from scipy.stats import linregress, shapiro, spearmanr\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "base_proj_dir = \"Z:/data/CCB\" ## base project directory\n",
    "save_dir = os.path.join(base_proj_dir, \"derivatives/simulations/crdm/simulation2\") ## save directory for CRDM simulations\n",
    "if not os.path.exists(save_dir): ## new Ss\n",
    "    os.makedirs(save_dir) ## make new Ss save directory\n",
    "\n",
    "def pd_extend(df_dest, df_extending):\n",
    "    \"\"\" Concatenates all subjects dataframe for saving current Ss parameters\n",
    "        INPUT:\n",
    "        - df_dest: destination dataframe to which second dataframe will be appended\n",
    "        - df_extending: dataframe to be added to the destination dataframe\n",
    "        OUTPUT:\n",
    "        - Concatenated dataframe containing info from currently iterated Ss\n",
    "    \"\"\"\n",
    "    return pd.concat([df_dest, df_extending])\n",
    "\n",
    "def SVs(alpha, beta, lottery_value, certain_value, ambiguity, probability):\n",
    "    \"\"\" Calculate SV for lottery and safe options given current trial condition combo (Gilboa & Schmeidler, 1989)\n",
    "        *Note: np.sign() and np.abs() allows this function to flexibly handle *both* gain and loss trials\n",
    "        INPUT:\n",
    "        - alpha: current Ss alpha\n",
    "        - beta: current Ss beta\n",
    "        - lottery_value: winning lottery amount for current condition combo\n",
    "        - ambiguity: ambiguity level for current condition combo\n",
    "        - probability: probability for current condition combo\n",
    "        OUTPUT:\n",
    "        - SV_lottery: subjective value for lottery option for current trial condition combination\n",
    "        - SV_certain: subjective value for certain option fr current trial condition combination\n",
    "    \"\"\"\n",
    "    SV_lottery = (probability - beta * ambiguity / 2) * lottery_value**alpha\n",
    "    SV_certain = certain_value**alpha\n",
    "    return SV_lottery, SV_certain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_per_subgroup = 2 ## number of trials per probability/lottery combo\n",
    "\n",
    "lottery_range = [8, 25, 40, 50] ## possible winning lottery values\n",
    "certain_value = 5 ## value of safe option\n",
    "## setting up variable arrays for parallel computations\n",
    "ambiguities_extend   = np.array([0.24,  0.5,  0.74,     0,    0,    0,    0,    0]) ## ambiguities for all amb/prob pairing\n",
    "probabilities_extend = np.array([ 0.5,  0.5,   0.5,  0.13, 0.25, 0.38, 0.50, 0.75]) ## probabilties for all amb/prob pairing\n",
    "lotteries = np.array([])\n",
    "ambiguities = np.array([])\n",
    "probabilities = np.array([])\n",
    "extend_len = len(ambiguities_extend)\n",
    "for i, lott in enumerate(lottery_range): ## for each of the four possible lottery values\n",
    "    lotteries = np.hstack((lotteries, np.ones(extend_len) * lott)) ## adds current lott value in quantity of ambiguities_extend (8)\n",
    "    ambiguities = np.hstack((ambiguities, ambiguities_extend)) ## adds ambiguity_extend as many times as lottery_range is long (4)\n",
    "    probabilities = np.hstack((probabilities, probabilities_extend)) ## adds probabilities_extend as many times as lottery_range is long (4)\n",
    "total_trials = n_trials_per_subgroup * len(lotteries) ## total number of trials per pain condition\n",
    "print(total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Alpha and Beta bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_alphas = []\n",
    "possible_betas = []\n",
    "probabilities_b = [0.13, 0.25, 0.38, 0.50, 0.75]\n",
    "ambiguities_b = [0.24, 0.5, 0.74]\n",
    "\n",
    "for this_prob in probabilities_b: ## for each probability level\n",
    "    for this_val in lottery_range: ## and each lottery value level\n",
    "        possible_alphas.append(np.log(this_prob)/np.log(certain_value/this_val)) ## append bound for current trial's variable level combo\n",
    "possible_alphas = np.array(possible_alphas) ## convert list to a numpy array\n",
    "print(\"ALPHA Bounds: [\", np.amin(possible_alphas), \",\", np.amax(possible_alphas), \"]\") ## print to output the lowest and highest beta bound\n",
    "\n",
    "for this_amb in ambiguities_b: ## for each ambiguity level\n",
    "    possible_betas.append(-1/this_amb) ## append lower bound for current beta\n",
    "    possible_betas.append(1/this_amb) ## append upper bound for current beta\n",
    "possible_betas = np.array(possible_betas) ## convert list to a numpy array\n",
    "print(\"BETA Bounds: [\", np.amin(possible_betas), \",\", np.amax(possible_betas), \"]\") ## print to output the lowest and highest beta bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Softmax Choice Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_likelihood(alpha, beta, x,n,  lottery_value, certain_value, ambiguity, probability):\n",
    "    \"\"\" Calculates binomial LL for each parameter combination.\n",
    "        *See above notes for why we can use our own math rather than rely on bernoulli.logpmf()\n",
    "        *Deals with positive infinity values by assigning a value of 0. \n",
    "        Then MLE functions, parameter pairs with a 0 LL score are removed.\n",
    "        INPUT:\n",
    "        - alpha: current Ss risk parameter [high values indicate risk seeking]\n",
    "        - beta: current Ss ambiguity parameter [high values indicate ambiguity avoidance]\n",
    "        - gamma: current Ss choice stochasticity parameter [high values indicate more noise]\n",
    "        - y: summation of lottery choices in condition subgroup\n",
    "        - n: number of trials per condition combo\n",
    "        - lottery_value: current condition combo winning lottery amount \n",
    "        - certain_value: current condition combo certain amount\n",
    "        - ambiguity: current condition combo ambiguity level\n",
    "        - probability: current condition combo probability level\n",
    "        OUTPUT:\n",
    "        - log_likelihood: relative score representing probabilty data resulted from current parameter combo\n",
    "    \"\"\"\n",
    "    p = probability_of_lottery_choice(alpha, beta, lottery_value, certain_value, ambiguity, probability)\n",
    "    log_likelihood = (np.log(p[0]) * x + np.log(1 - p[0]) * (n - x))\n",
    "    log_likelihood[log_likelihood == np.inf] = 0\n",
    "    return log_likelihood\n",
    "\n",
    "def make_data_and_recover(p_alpha, p_beta, pid, df):\n",
    "    \"\"\" Executes parameter estimation and saves results to df_participants dataframe.\n",
    "        INPUT:\n",
    "        - p_alpha: current simulation Ss alpha value\n",
    "        - p_beta: current simulation Ss beta value\n",
    "        - pid: current simulation Ss subject ID\n",
    "        - df: Ss dataframe with all previous Ss information (adds by extending current Ss df)\n",
    "        OUPUT:\n",
    "        - *res: recovered alpha, recovered beta\n",
    "        - df: extended df_participants dataframe\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for i, amb in enumerate(ambiguities):\n",
    "        subset_trials = np.random.random(size = n_trials_per_subgroup) ## simulated randomness of choice\n",
    "        p_true = probability_of_lottery_choice(p_alpha, p_beta, lotteries[i], certain_value, amb, probabilities[i])\n",
    "        idx = np.where(subset_trials <= p_true[0])\n",
    "        sv_lott = p_true[1]\n",
    "        sv_safe = p_true[2]\n",
    "        subset_trials[:] = 0\n",
    "        subset_trials[idx] = 1 ## error prone, real trials\n",
    "        #subset_trials[:int(np.round(n_trials_per_subgroup*p_true))] = 1 ## perfect circumstances, no noise\n",
    "        data = [pid, p_alpha, p_beta, None, None, lotteries[i], certain_value, amb, probabilities[i], sv_lott, sv_safe]\n",
    "        data = [[a] * n_trials_per_subgroup for a in data]\n",
    "        data.append(subset_trials)\n",
    "        data = np.array(data).T\n",
    "        df = pd_extend(df, pd.DataFrame(data, columns=df.columns))\n",
    "        lottery_chosen_x = np.sum(subset_trials)\n",
    "        pairs.append((lottery_chosen_x, n_trials_per_subgroup))\n",
    "    res = MLE_alpha(np.array(pairs), lotteries, certain_value, ambiguities, probabilities)\n",
    "    res = MLE_beta(np.array(pairs), res, lotteries, certain_value, ambiguities, probabilities)\n",
    "    data = [pid, p_alpha, p_beta, res[0], res[1], None, None, None, None, None, None, None]\n",
    "    data = np.array([[a] for a in data]).T\n",
    "    df = pd_extend(df, pd.DataFrame(data, columns=df.columns))\n",
    "    return *res, df\n",
    "\n",
    "def MLE_alpha(pairs, lotteries, certain_value, ambiguities, probabilities):\n",
    "    \"\"\" Grid search of alpha and gamma parameter space to determine which point produces the maximum log likelihood score. \n",
    "        *Risk trials only*\n",
    "        *Notes: Conceptualize parameter and probability space as two parallel multidimensional spaces. \n",
    "                Using a \"grid search\" method, we carefully iterate through a 2D parameter space (alpha/gamma) \n",
    "                to determine which point best explains the data, quantified as the maximum likelihood score.\n",
    "        INPUT:\n",
    "        ** Numpy parallel arrays **\n",
    "        - pairs: Ss choices for all condition subgroups\n",
    "        - lotteries: winning lottery amounts for conditon subgroups\n",
    "        - certain_values: certain amounts for condition subgroups\n",
    "        - ambiguities: ambiguity level for condition subgroups\n",
    "        - probabilities: probability level for condition subgroups\n",
    "        OUTPUT:\n",
    "        - Tuple containing best fit parameters (alpha and gamma)\n",
    "    \"\"\"\n",
    "    best_fit = None\n",
    "    max_likelihood = None\n",
    "    x,n = pairs[:, 0], pairs[:, 1]\n",
    "    idx = np.where(ambiguities == 0)\n",
    "    for alpha in np.round(np.arange(0.3, 2, 0.01), 2): ## grid search - part 1 (fit alpha first)\n",
    "        ## sums log likelihoods of all condition subgroups (beta held constant at 0, as is ambiguity level)\n",
    "        likelihood = np.nansum(binomial_likelihood(alpha, 0, x[idx], n[idx], lotteries[idx], \n",
    "                                                    certain_value, ambiguities[idx], probabilities[idx]))\n",
    "        if max_likelihood is None or likelihood > max_likelihood:\n",
    "            max_likelihood = likelihood\n",
    "            best_fit = alpha\n",
    "    return best_fit\n",
    "\n",
    "def MLE_beta(pairs, alpha, lotteries, certain_value, ambiguities, probabilities):\n",
    "    \"\"\" Grid search of beta parameter space to determine which point produces maximum log likelihood score. \n",
    "        *Ambiguity trials only*\n",
    "        *Notes: Conceptualize parameter and probability space as two parallel multidimensional spaces. \n",
    "        Using a \"grid search\" method previously to determine the best fit of alpha and gamma parameters,\n",
    "        we can use those values to now guide our search through 1D beta space.\n",
    "        INPUT:\n",
    "        ** Numpy parallel arrays **\n",
    "        - pairs: Ss choices for all condition subgroups\n",
    "        - lotteries: winning lottery amounts for conditon subgroups\n",
    "        - certain_values: certain amounts for condition subgroups\n",
    "        - ambiguities: ambiguity level for condition subgroups\n",
    "        - probabilities: probability level for condition subgroups\n",
    "        OUTPUT:\n",
    "        - Tuple containing best fit parameters (alpha, beta, and gamma)\n",
    "    \"\"\"\n",
    "    best_fit = None\n",
    "    max_likelihood = None\n",
    "    x,n = pairs[:, 0], pairs[:, 1]\n",
    "    idx = np.where(ambiguities != 0)\n",
    "    for beta in np.round(np.arange(-1.3, 1.31, 0.01), 2): ## grid search - part 2 (fit beta second)\n",
    "        ## sums log likelihoods of all condition subgroups (trials where ambiguity isn't 0)\n",
    "        likelihood = np.nansum(binomial_likelihood(alpha, beta, x[idx], n[idx], lotteries[idx], \n",
    "                                                    certain_value, ambiguities[idx], probabilities[idx]))\n",
    "        if max_likelihood is None or likelihood > max_likelihood:\n",
    "            max_likelihood = likelihood\n",
    "            best_fit = (alpha, beta)\n",
    "    return best_fit\n",
    "\n",
    "def probability_of_lottery_choice(alpha, beta, lottery_value, certain_value, ambiguity, probability, gamma = 1.5): \n",
    "    \"\"\" Determines probability of selecting lottery using the Softmax probabilitic function\n",
    "        INPUT:\n",
    "        - alpha: current Ss risk parameter [high values indicate risk seeking]\n",
    "        - beta: current Ss ambiguity parameter [high values indicate ambiguity avoidance]\n",
    "        - gamma: current Ss choice stochasticity parameter [high values indicate more noise]\n",
    "        - lottery_value: current condition combo winning lottery amount \n",
    "        - certain_value: current condition combo certain amount\n",
    "        - ambiguity: current condition combo ambiguity level\n",
    "        - probability: current condition combo probability level\n",
    "        OUTPUT:\n",
    "        - Ss probability of choosing lottery for trials with the current condition combination \n",
    "    \"\"\"\n",
    "    SV_lottery, SV_certain = SVs(alpha, beta, lottery_value, certain_value, ambiguity, probability)\n",
    "    return 1 / (1 + np.exp(-gamma * (SV_lottery - SV_certain))), SV_lottery, SV_certain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Softmax #1**\n",
    "- Simulating across beta\n",
    "- Alpha and gamma held constant (0.6, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.array([0.6])\n",
    "#betas = np.round(np.arange(-1.3, 1.31, 2.6/498), 2)\n",
    "betas = np.round(np.arange(-4.17, 4.17, 8.34/500), 2) ## 500 steps\n",
    "print(\"Number of Simulations:\", len(alphas)*len(betas))\n",
    "df = pd.DataFrame() ## new dataframe for correlation plot\n",
    "\n",
    "## dataframe containing all Ss values to be saved to CSV\n",
    "df_participants = pd.DataFrame(columns=[\"PID\", \n",
    "                                        \"Simulation Alpha\", \"Simulation Beta\", \n",
    "                                        \"Recovered Alpha\", \"Recovered Beta\", \n",
    "                                        \"Lottery Value\", \"Safe Value\", \n",
    "                                        \"Ambiguity\", \"Probability\", \n",
    "                                        \"SV Lottery\", \"SV Safe\", \n",
    "                                        \"Choice\"])\n",
    "recovered_betas = []\n",
    "pid = 1\n",
    "for p_alpha in alphas:\n",
    "    for p_beta in betas:\n",
    "        alpha_r, beta_r, df_participants = make_data_and_recover(p_alpha, p_beta, pid, df_participants)\n",
    "        recovered_betas.append(beta_r)\n",
    "        print(pid, end = \"\\r\")\n",
    "        pid += 1      \n",
    "filename2 = os.path.join(save_dir, \"simulation2SM_cAvBcG-2trials.csv\") ## path/filename to save file\n",
    "df_participants.to_csv(filename2) ## save DF to csv\n",
    "beta_x = betas.tolist() * alphas.shape[0] ## reshape beta list\n",
    "fit_line = linregress(beta_x, recovered_betas) ## create regression line\n",
    "fit_stat = spearmanr(beta_x, recovered_betas) ## non-normal distribution\n",
    "line_y = np.array(beta_x) * fit_line.slope + fit_line.intercept\n",
    "residuals = np.array(recovered_betas) - line_y ## get residual for each beta point\n",
    "print(\"Shapiro-Wilk Test of Normality:\", shapiro(np.abs(residuals))[:]) ## print outcome of normality test\n",
    "print(\"Spearmans Rho^2:\", fit_stat[:]) ## print Spearman's Rho^2 (non-parameter correlation)\n",
    "print(\"Residual SD:\", np.std(residuals)) ## print SD of the residuals\n",
    "df[\"Simulated β\"] = beta_x ## assign x axis values\n",
    "df[\"Fit β\"] = recovered_betas ## assign y axis values\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax = sns.regplot(x = \"Simulated β\", y = \"Fit β\", data = df, color = \"#26B64A\") ## use seaborn regplot\n",
    "sns.despine(top = True) ## remove upper and right plot blox line\n",
    "ax.set_ylabel(\"Fit β\", fontsize=16) ## set font size for y axis\n",
    "ax.set_xlabel(\"Simulated β\", fontsize=16) ## set font size for x axis\n",
    "## set title for figure to include important stats\n",
    "plt.suptitle(\"n={5} (α=0.6) | Shapiro-Wilk={0:.2f}, p={1:.2f}** | Spearmans Rho^2={2:.2f}, p={3:.2f}** | Residual SD={4:.2f}\" .format(shapiro(np.abs(residuals))[0], \n",
    "                                                                                                                                    shapiro(np.abs(residuals))[1],\n",
    "                                                                                                                                    fit_stat[0]**2, fit_stat[1], \n",
    "                                                                                                                                    np.std(residuals),\n",
    "                                                                                                                                    len(beta_x)), \n",
    "                                                                                                                                    fontsize=12)\n",
    "fig_name = os.path.join(save_dir, \"simulation2SM_cAvBcG-2trials.png\") ## directory and filename for beta plot\n",
    "print(\"Saving to: {}\".format(fig_name)) ## indicate save directory\n",
    "plt.savefig(fig_name) ## save plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Softmax #2**\n",
    "- Simulating across alpha and beta\n",
    "- Gamma held constant (1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.round(np.arange( 0.3,  1.2,     0.05), 2) ## 18 steps\n",
    "betas = np.round(np.arange(-4.17, 4.17, 8.34/500), 2) ## 500 steps\n",
    "print(\"Number of Simulations:\", len(alphas)*len(betas))\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df_participants = pd.DataFrame(columns=[\"PID\", \n",
    "                                        \"Simulation Alpha\", \"Simulation Beta\", \n",
    "                                        \"Recovered Alpha\", \"Recovered Beta\", \n",
    "                                        \"Lottery Value\", \"Safe Value\", \n",
    "                                        \"Ambiguity\", \"Probability\", \n",
    "                                        \"SV Lottery\", \"SV Safe\", \n",
    "                                        \"Choice\"])\n",
    "recovered_betas = []\n",
    "pid = 1\n",
    "for p_alpha in alphas:\n",
    "    for p_beta in betas:\n",
    "        alpha_r, beta_r, df_participants = make_data_and_recover(p_alpha, p_beta, pid, df_participants)\n",
    "        recovered_betas.append(beta_r)\n",
    "        print(pid, end = \"\\r\")\n",
    "        pid += 1      \n",
    "filename = os.path.join(save_dir, \"simulation2SM_vAvBcG-2trials.csv\")\n",
    "df_participants.to_csv(filename)\n",
    "        \n",
    "beta_x = betas.tolist() * alphas.shape[0]\n",
    "fit_line = linregress(beta_x, recovered_betas)\n",
    "fit_stat = spearmanr(beta_x, recovered_betas)\n",
    "line_y = np.array(beta_x) * fit_line.slope + fit_line.intercept\n",
    "residuals = np.array(recovered_betas) - line_y\n",
    "print(\"Shapiro-Wilk Test of Normality:\", shapiro(np.abs(residuals))[:])\n",
    "print(\"Spearmans Rho^2:\", fit_stat[:])\n",
    "print(\"Residual SD:\", np.std(residuals))\n",
    "df[\"Simulated β\"] = beta_x\n",
    "df[\"Fit β\"] = recovered_betas\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax = sns.regplot(x = \"Simulated β\", y = \"Fit β\", data = df)\n",
    "sns.despine(top = True)\n",
    "ax.set_ylabel(\"Fit β\", fontsize=16)\n",
    "ax.set_xlabel(\"Simulated β\", fontsize=16)\n",
    "plt.suptitle(\"n={5} (α[0.3,1.2,0.05]) | Shapiro-Wilk={0:.2f}, p={1:.2f}** | Spearmans Rho^2={2:.2f}, p={3:.2f}** | Residual SD={4:.2f}\" .format(shapiro(np.abs(residuals))[0], \n",
    "                                                                                                                                                shapiro(np.abs(residuals))[1], \n",
    "                                                                                                                                                fit_stat[0], fit_stat[1], \n",
    "                                                                                                                                                np.std(residuals),\n",
    "                                                                                                                                                len(beta_x)), \n",
    "                                                                                                                                                fontsize=12)\n",
    "fig_name = os.path.join(save_dir, \"simulation2SM_vAvBcG-2trials.png\")\n",
    "print(\"Saving to: {}\".format(fig_name))\n",
    "plt.savefig(fig_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
