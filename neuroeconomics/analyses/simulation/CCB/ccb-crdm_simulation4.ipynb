{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CRDM Beta Simulation (CCB Project): Version 4**\n",
    "\n",
    "#### Softmax vs Luce Choice Models\n",
    "#### - Alpha [0.3, 1.2, 0.05] vs alpha constant [0.6]\n",
    "#### - Beta [-1.3, 1.31, 2.6/498], obtaining 500 steps (*simulated subjects*)\n",
    "#### - Gamma [0.5, 8, 0.5] | Mu [0.5, 0.7, 0.01]\n",
    "\n",
    "##### **Version 4 Improvements** -- Simulates data across stochasticity parameters (gamma/mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===================\n",
    "Mandy Renfro (2024)\n",
    "===================\n",
    "\"\"\"\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.seterr(all = \"ignore\") #disable numpy error prints in output\n",
    "import os\n",
    "import os.path, sys\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style = \"white\", palette = \"muted\")\n",
    "from scipy.stats import linregress, shapiro, spearmanr\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "base_proj_dir = \"Z:/data/CCB\" ## base project directory\n",
    "save_dir = os.path.join(base_proj_dir, \"derivatives/simulations/crdm/simulation4\") ## save directory for CRDM simulations\n",
    "if not os.path.exists(save_dir): ## new Ss\n",
    "    os.makedirs(save_dir) ## make new Ss save directory\n",
    "\n",
    "def pd_extend(df_dest, df_extending):\n",
    "    \"\"\" Concatenates all subjects dataframe for saving current Ss parameters\n",
    "        INPUT:\n",
    "        - df_dest: destination dataframe to which second dataframe will be appended\n",
    "        - df_extending: dataframe to be added to the destination dataframe\n",
    "        OUTPUT:\n",
    "        - Concatenated dataframe containing info from currently iterated Ss\n",
    "    \"\"\"\n",
    "    ## concatenates dataframe for saving simulated data\n",
    "    return pd.concat([df_dest, df_extending])\n",
    "\n",
    "def SVs(alpha, beta, lottery_value, certain_value, ambiguity, probability):\n",
    "    \"\"\" Calculate SV for lottery and safe options given the current trial condition combination (Gilboa & Schmeidler, 1989)\n",
    "        *Note: np.sign() and np.abs() allows this function to flexibly handle *both* gain and loss trials\n",
    "        INPUT:\n",
    "        - alpha: current Ss alpha\n",
    "        - beta: current Ss beta\n",
    "        - lottery_value: winning lottery amount for current condition combo\n",
    "        - ambiguity: ambiguity level for current condition combo\n",
    "        - probability: probability for current condition combo\n",
    "        OUTPUT:\n",
    "        - SV_lottery: subjective value for lottery option for current trial condition combination\n",
    "        - SV_certain: subjective value for certain option fr current trial condition combination\n",
    "    \"\"\"\n",
    "    SV_lottery = (probability - beta * ambiguity / 2) * lottery_value**alpha\n",
    "    SV_certain = certain_value**alpha\n",
    "    return SV_lottery, SV_certain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials_per_subgroup = 2 ## number of trials per probability/lottery combo\n",
    "\n",
    "lottery_range = [8, 25, 40, 50] ## possible winning lottery values\n",
    "certain_value = 5 ## value of safe option\n",
    "## setting up variable arrays for parallel computations\n",
    "ambiguities_extend   = np.array([0.24,  0.5,  0.74,     0,    0,    0,    0,    0]) ## ambiguities for all amb/prob pairing\n",
    "probabilities_extend = np.array([ 0.5,  0.5,   0.5,  0.13, 0.25, 0.38, 0.50, 0.75]) ## probabilties for all amb/prob pairing\n",
    "lotteries = np.array([])\n",
    "ambiguities = np.array([])\n",
    "probabilities = np.array([])\n",
    "extend_len = len(ambiguities_extend) ## length of times to duplicate each lottery value\n",
    "for i, lott in enumerate(lottery_range): ## for each of the four possible lottery values\n",
    "    lotteries = np.hstack((lotteries, np.ones(extend_len) * lott)) ## adds current lott value in quantity of ambiguities_extend (8)\n",
    "    ambiguities = np.hstack((ambiguities, ambiguities_extend)) ## adds ambiguity_extend as many times as lottery_range is long (4)\n",
    "    probabilities = np.hstack((probabilities, probabilities_extend)) ## adds probabilities_extend as many times as lottery_range is long (4)\n",
    "total_trials = n_trials_per_subgroup * len(lotteries) ## total number of trials per pain condition\n",
    "print(total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Softmax Choice Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_likelihood_SM(alpha, beta, gamma, y, n,  lottery_value, certain_value, ambiguity, probability):\n",
    "    \"\"\" Calculates binomial LL for each parameter combination\n",
    "        *See above notes for why we can use our own math rather than rely on bernoulli.logpmf()\n",
    "        *Deals with positive infinity values by assigning a value of 0. Then the MLE functions, \n",
    "        parameter pairs with a 0 LL score are removed.\n",
    "        INPUT:\n",
    "        - alpha: current Ss risk parameter [high values indicate risk seeking]\n",
    "        - beta: current Ss ambiguity parameter [high values indicate ambiguity avoidance]\n",
    "        - gamma: current Ss choice stochasticity parameter [high values indicate more noise]\n",
    "        - y: summation of lottery choices in condition subgroup\n",
    "        - n: number of trials per condition combo\n",
    "        - lottery_value: current condition combo winning lottery amount \n",
    "        - certain_value: current condition combo certain amount\n",
    "        - ambiguity: current condition combo ambiguity level\n",
    "        - probability: current condition combo probability level\n",
    "        OUTPUT:\n",
    "        - log_likelihood: relative score representing probabilty data resulted from current parameter combo\n",
    "    \"\"\"\n",
    "    p = probability_of_lottery_choice_SM(alpha, beta, gamma, lottery_value, certain_value, ambiguity, probability)\n",
    "    log_likelihood = (np.log(p[0]) * y + np.log(1 - p[0]) * (n - y))\n",
    "    log_likelihood[log_likelihood == np.inf] = 0\n",
    "    return log_likelihood\n",
    "\n",
    "def make_data_and_recover_SM(p_alpha, p_beta, p_gamma, pid, df):\n",
    "    \"\"\" Executes parameter estimation and saves results to df_participants dataframe.\n",
    "        INPUT:\n",
    "        - p_alpha: current simulation Ss alpha value\n",
    "        - p_beta: current simulation Ss beta value\n",
    "        - pid: current simulation Ss subject ID\n",
    "        - df: Ss dataframe with all previous Ss information (adds by extending current Ss df)\n",
    "        OUPUT:\n",
    "        - *res: recovered alpha, recovered beta, recovered gamma\n",
    "        - df: extended df_participants dataframe\n",
    "    \"\"\"\n",
    "    pairs = []  \n",
    "    all_data = None \n",
    "    for i, amb in enumerate(ambiguities):\n",
    "        subset_trials = np.random.random(size = n_trials_per_subgroup) ## simulated randomness of choice\n",
    "        p_true = probability_of_lottery_choice_SM(p_alpha, p_beta, p_gamma, lotteries[i], certain_value, amb, probabilities[i])\n",
    "        idx = np.where(subset_trials <= p_true[0])\n",
    "        sv_lott = p_true[1]\n",
    "        sv_safe = p_true[2]\n",
    "        subset_trials[:] = 0\n",
    "        subset_trials[idx] = 1 ## error prone, real trials\n",
    "        #subset_trials[:int(np.round(n_trials_per_subgroup*p_true))] = 1 ## perfect circumstances, no noise\n",
    "        ## save data to df\n",
    "        data = [pid, p_alpha, p_beta, p_gamma, None, None, None, lotteries[i], certain_value, amb, probabilities[i], sv_lott, sv_safe]\n",
    "        data = [[a] * n_trials_per_subgroup for a in data]\n",
    "        data.append(subset_trials)\n",
    "        data = np.array(data).T\n",
    "        if all_data is None:\n",
    "            all_data = data\n",
    "        else:\n",
    "            all_data = np.vstack((all_data, data))\n",
    "        lottery_chosen_x = np.sum(subset_trials)\n",
    "        pairs.append((lottery_chosen_x, n_trials_per_subgroup))\n",
    "    res = MLE_alpha_gamma_SM(np.array(pairs), lotteries, certain_value, ambiguities, probabilities)\n",
    "    res = MLE_beta_SM(np.array(pairs), res[0], res[1], lotteries, certain_value, ambiguities, probabilities)\n",
    "    df = pd_extend(df, pd.DataFrame(all_data, columns = df.columns))\n",
    "    idx = np.where(df[\"Recovered Alpha\"].values == None)\n",
    "    df[\"Recovered Alpha\"].values[idx] = res[0]\n",
    "    df[\"Recovered Beta\"].values[idx] = res[1]\n",
    "    df[\"Recovered Gamma\"].values[idx] = res[2]\n",
    "    return *res, df\n",
    "\n",
    "def MLE_alpha_gamma_SM(pairs, lotteries, certain_value, ambiguities, probabilities):\n",
    "    \"\"\" Grid search of alpha and gamma parameter space to determine which point produces maximum log likelihood score. \n",
    "        *Risk trials only*\n",
    "        *Notes: Conceptualize parameter and probability space as two parallel multidimensional spaces. \n",
    "                Using a \"grid search\" method, we carefully iterate through a 2D parameter space (alpha/gamma) \n",
    "                to determine which point best explains the data, quantified as the maximum likelihood score.\n",
    "        INPUT:\n",
    "        ** Numpy parallel arrays **\n",
    "        - pairs: Ss choices for all condition subgroups\n",
    "        - lotteries: winning lottery amounts for conditon subgroups\n",
    "        - certain_values: certain amounts for condition subgroups\n",
    "        - ambiguities: ambiguity level for condition subgroups\n",
    "        - probabilities: probability level for condition subgroups\n",
    "        OUTPUT:\n",
    "        - Tuple containing best fit parameters (alpha and gamma)\n",
    "    \"\"\"\n",
    "    best_fit = None\n",
    "    max_likelihood = None\n",
    "    y, n = pairs[:, 0], pairs[:, 1]\n",
    "    idx = np.where(ambiguities == 0)\n",
    "    for alpha in np.round(np.arange(    0.3, 2, 0.01), 2): ## grid search - part 1 (fit alpha first)\n",
    "        for gamma in np.round(np.arange(0.5, 8, 0.10), 2):\n",
    "            ## sums log likelihoods of all condition subgroups (beta held constant at 0, as is ambiguity level)\n",
    "            likelihood = np.nansum(binomial_likelihood_SM(alpha, 0, gamma, y[idx], n[idx], lotteries[idx], certain_value, ambiguities[idx], probabilities[idx]))\n",
    "            if max_likelihood is None or likelihood > max_likelihood:\n",
    "                max_likelihood = likelihood\n",
    "                best_fit = (alpha, gamma)\n",
    "    return best_fit\n",
    "\n",
    "def MLE_beta_SM(pairs, alpha, gamma, lotteries, certain_value, ambiguities, probabilities):\n",
    "    \"\"\" Grid search of beta parameter space to determine which point produces maximum log likelihood score. \n",
    "        *Ambiguity trials only*\n",
    "        *Notes: Conceptualize parameter and probability space as two parallel multidimensional spaces. \n",
    "        Using a \"grid search\" method previously to determine the best fit of alpha and gamma parameters,\n",
    "        we can use those values to now guide our search through 1D beta space.\n",
    "        INPUT:\n",
    "        ** Numpy parallel arrays **\n",
    "        - pairs: Ss choices for all condition subgroups\n",
    "        - lotteries: winning lottery amounts for conditon subgroups\n",
    "        - certain_values: certain amounts for condition subgroups\n",
    "        - ambiguities: ambiguity level for condition subgroups\n",
    "        - probabilities: probability level for condition subgroups\n",
    "        OUTPUT:\n",
    "        - Tuple containing best fit parameters (alpha, beta, and gamma)\n",
    "    \"\"\"\n",
    "    best_fit = None\n",
    "    max_likelihood = None\n",
    "    y, n = pairs[:, 0], pairs[:, 1]\n",
    "    idx = np.where(ambiguities != 0)\n",
    "    for beta in np.round(np.arange(-1.3, 1.31, 0.01), 2): ## grid search - part 2 (fit beta second)\n",
    "        ## sums log likelihoods of all condition subgroups (trials where ambiguity isn't 0)\n",
    "        likelihood = np.nansum(binomial_likelihood_SM(alpha, beta, gamma, y[idx], n[idx], lotteries[idx], certain_value, ambiguities[idx], probabilities[idx]))\n",
    "        if max_likelihood is None or likelihood > max_likelihood:\n",
    "            max_likelihood = likelihood\n",
    "            best_fit = (alpha, beta, gamma)\n",
    "    return best_fit\n",
    "\n",
    "def probability_of_lottery_choice_SM(alpha, beta, gamma, lottery_value, certain_value, ambiguity, probability):\n",
    "    \"\"\" Determines probability of selecting lottery using the Softmax probabilitic function\n",
    "        INPUT:\n",
    "        - alpha: current Ss risk parameter [high values indicate risk seeking]\n",
    "        - beta: current Ss ambiguity parameter [high values indicate ambiguity avoidance]\n",
    "        - gamma: current Ss choice stochasticity parameter [high values indicate more noise]\n",
    "        - lottery_value: current condition combo winning lottery amount \n",
    "        - certain_value: current condition combo certain amount\n",
    "        - ambiguity: current condition combo ambiguity level\n",
    "        - probability: current condition combo probability level\n",
    "        OUTPUT:\n",
    "        - Ss probability of choosing lottery for trials with the current condition combo\n",
    "        - SV_lottery: SV for current lottery option\n",
    "        - SV_certain: SV for current safe option\n",
    "    \"\"\"\n",
    "    SV_lottery, SV_certain = SVs(alpha, beta, lottery_value, certain_value, ambiguity, probability)\n",
    "    return 1 / (1 + np.exp(-gamma * (SV_lottery - SV_certain))), SV_lottery, SV_certain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Softmax #1**\n",
    "- Simulating across beta and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Participant parameter space (~7,500 simulated subs)\n",
    "alphas = np.array([0.6]) ## 1 step\n",
    "betas  = np.round(np.arange(-1.3, 1.31, 2.6/498), 3) ## 500 steps\n",
    "gammas = np.round(np.arange( 0.5,    8,     0.5), 2) ## 16 steps\n",
    "print(\"Number of Simulations:\", len(alphas)*len(betas)*len(gammas))\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df_participants = pd.DataFrame(columns=[\"PID\", \n",
    "                                        \"Simulated Alpha\", \"Simulated Beta\", \"Simulated Gamma\", \n",
    "                                        \"Recovered Alpha\", \"Recovered Beta\", \"Recovered Gamma\",\n",
    "                                        \"Lottery Value\", \"Safe Value\", \n",
    "                                        \"Ambiguity\", \"Probability\", \n",
    "                                        \"SV Lottery\", \"SV Safe\",\n",
    "                                        \"Choice\"])\n",
    "recovered_betas = []\n",
    "pid = 1\n",
    "for p_gamma in gammas:\n",
    "    for p_alpha in alphas:\n",
    "        for p_beta in betas:\n",
    "            r_alpha, r_beta, r_gamma, df_participants = make_data_and_recover_SM(p_alpha, p_beta, p_gamma, pid, df_participants)\n",
    "            recovered_betas.append(r_beta)\n",
    "            print(pid, end = \"\\r\")\n",
    "            pid += 1  \n",
    "filename = os.path.join(save_dir, \"simulation4SM_cAvBvG-2trials.csv\")\n",
    "df_participants.to_csv(filename)\n",
    "\n",
    "beta_x = betas.tolist() * (alphas.shape[0] * gammas.shape[0])\n",
    "fit_line = linregress(beta_x, recovered_betas)\n",
    "fit_stat = spearmanr(beta_x, recovered_betas)\n",
    "line_y = np.array(beta_x) * fit_line.slope + fit_line.intercept\n",
    "residuals = np.array(beta_x) - np.array(recovered_betas)\n",
    "print(\"Shapiro-Wilk Test of Normality:\", shapiro(np.abs(residuals))[:])\n",
    "print(\"Spearmans Rho^2:\", fit_stat[:])\n",
    "print(\"Residual SD:\", np.std(residuals))\n",
    "df[\"Simulated β (Softmax)\"] = beta_x\n",
    "df[\"Fit β\"] = recovered_betas\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.regplot(x = \"Simulated β (Softmax)\", y = \"Fit β\", data = df, color = \"#26B64A\")\n",
    "sns.despine(top = True)\n",
    "ax.set_ylabel(\"Fit β\", fontsize=16)\n",
    "ax.set_xlabel(\"Simulated β (Softmax)\", fontsize=16)\n",
    "plt.suptitle(\"n={5} (α=0.6, ɣ=[0.5,8,0.5]) | Shapiro-Wilk={0:.2f}, p={1:.2f}** | Spearmans Rho^2={2:.2f}, p={3:.2f}** | Residual SD={4:.2f}\".format(shapiro(np.abs(residuals))[0], \n",
    "                                                                                                                                                    shapiro(np.abs(residuals))[1], \n",
    "                                                                                                                                                    fit_stat[0]**2, fit_stat[1], \n",
    "                                                                                                                                                    np.std(residuals), \n",
    "                                                                                                                                                    len(beta_x)), \n",
    "                                                                                                                                                    fontsize = 12)\n",
    "fig_name = os.path.join(save_dir, \"simulation4SM_cAvBvG-2trials.png\")\n",
    "print(\"Saving to: {}\".format(fig_name))\n",
    "plt.savefig(fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Softmax #2** \n",
    "- Simulating across alpha, beta, and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Participant parameter space (~14,310 simulated subs)\n",
    "alphas = np.round(np.arange( 0.3,   1.2,  0.05), 2)\n",
    "betas  = np.round(np.arange(-1.3,  1.31,  0.05), 3) ## 52 steps\n",
    "gammas = np.round(np.arange( 0.5,     8,   0.5), 2) ## 16 steps\n",
    "print(\"Number of Simulations:\", len(alphas)*len(betas)*len(gammas))\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df_participants = pd.DataFrame(columns=[\"PID\", \n",
    "                                        \"Simulated Alpha\", \"Simulated Beta\", \"Simulated Gamma\", \n",
    "                                        \"Recovered Alpha\", \"Recovered Beta\", \"Recovered Gamma\",\n",
    "                                        \"Lottery Value\", \"Safe Value\", \n",
    "                                        \"Ambiguity\", \"Probability\",\n",
    "                                        \"SV Lottery\", \"SV Safe\",\n",
    "                                        \"Choice\"])\n",
    "pid = 1\n",
    "for p_gamma in gammas:\n",
    "    for p_alpha in alphas:\n",
    "        for p_beta in betas:\n",
    "            r_alpha, r_beta, r_gamma, df_participants = make_data_and_recover_SM(p_alpha, p_beta, p_gamma, pid, df_participants)\n",
    "            print(pid, end = \"\\r\")\n",
    "            pid += 1\n",
    "filename = os.path.join(save_dir, \"simulation4SM_vAvBvG-2trials.csv\")\n",
    "df_participants.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = glob(os.path.join(base_proj_dir, save_dir, \"simulation4SM_vAvBvG-2trials.csv\"))[0]\n",
    "df = pd.read_csv(file)\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "beta_x = df[\"Simulated Beta\"].values[::total_trials]\n",
    "fit_line = linregress(beta_x, df[\"Recovered Beta\"].values[::total_trials])\n",
    "fit_stat = spearmanr(beta_x, df[\"Recovered Beta\"].values[::total_trials]) ## non-normal distribution\n",
    "line_y = np.array(beta_x) * fit_line.slope + fit_line.intercept\n",
    "residuals = np.array(beta_x) - df[\"Recovered Beta\"].values[::total_trials]\n",
    "print(\"Shapiro-Wilk Test of Normality:\", shapiro(np.abs(residuals))[:])\n",
    "print(\"Spearmans Rho^2:\", fit_stat[:])\n",
    "print(\"Residual SD:\", np.std(residuals))\n",
    "df2[\"Simulated β (Softmax)\"] = df[\"Simulated Beta\"].values[::total_trials]\n",
    "df2[\"Fit β\"] = df[\"Recovered Beta\"].values[::total_trials]\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.regplot(x = \"Simulated β (Softmax)\", y = \"Fit β\", data = df2)\n",
    "sns.despine(top = True)\n",
    "ax.set_ylabel(\"Fit β\", fontsize=16)\n",
    "ax.set_xlabel(\"Simulated β (Softmax)\", fontsize=16)\n",
    "plt.suptitle(\"n={5} (α[0.3,1.2,0.05], ɣ=[0.5,8,0.5]) | Shapiro-Wilk={0:.2f}, p={1:.2f}** | Spearmans Rho^2={2:.2f}, p={3:.2f}** | Residual SD={4:.2f}\".format(shapiro(np.abs(residuals))[0], \n",
    "                                                                                                                                                            shapiro(np.abs(residuals))[1], \n",
    "                                                                                                                                                            fit_stat[0], \n",
    "                                                                                                                                                            fit_stat[1], \n",
    "                                                                                                                                                            np.std(residuals), \n",
    "                                                                                                                                                            len(beta_x)), \n",
    "                                                                                                                                                            fontsize = 12)\n",
    "fig_name = os.path.join(save_dir, \"simulation4SM_vAvBvG-2trials.png\")\n",
    "print(\"Saving to: {}\".format(fig_name))\n",
    "plt.savefig(fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Luce Choice Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_likelihood_LUCE(alpha, beta, mu, y, n, lottery_value, certain_value, ambiguity, probability):\n",
    "    p = probability_of_lottery_choice_LUCE(alpha, beta, mu, lottery_value, certain_value, ambiguity, probability)\n",
    "    log_likelihood = (np.log(p[0]) * y + np.log(1 - p[0]) * (n - y))\n",
    "    log_likelihood[log_likelihood == np.inf] = 0\n",
    "    return log_likelihood\n",
    "\n",
    "def make_data_and_recover_LUCE(p_alpha, p_beta, p_mu, pid, df):\n",
    "    pairs = []  \n",
    "    all_data = None \n",
    "    for i, amb in enumerate(ambiguities):\n",
    "        subset_trials = np.random.random(size = n_trials_per_subgroup) \n",
    "        p_true = probability_of_lottery_choice_LUCE(p_alpha, p_beta, p_mu, lotteries[i], certain_value, amb, probabilities[i])\n",
    "        idx = np.where(subset_trials <= p_true[0])\n",
    "        sv_lott = p_true[1]\n",
    "        sv_safe = p_true[2]\n",
    "        subset_trials[:] = 0\n",
    "        subset_trials[idx] = 1 ## error prone, real trials\n",
    "        #subset_trials[:int(np.round(n_trials_per_subgroup * p_true))] = 1 ## perfect circumstances, no noise\n",
    "        data = [pid, p_alpha, p_beta, p_mu, None, None, None, lotteries[i], certain_value, amb, probabilities[i], sv_lott, sv_safe]\n",
    "        data = [[a] * n_trials_per_subgroup for a in data]\n",
    "        data.append(subset_trials)\n",
    "        data = np.array(data).T\n",
    "        if all_data is None:\n",
    "            all_data = data\n",
    "        else:\n",
    "            all_data = np.vstack((all_data, data))\n",
    "        lottery_chosen_x = np.sum(subset_trials)\n",
    "        pairs.append((lottery_chosen_x, n_trials_per_subgroup))\n",
    "    res = MLE_alpha_mu_LUCE(np.array(pairs), lotteries, certain_value, ambiguities, probabilities)\n",
    "    res = MLE_beta_LUCE(np.array(pairs), res[0], res[1], lotteries, certain_value, ambiguities, probabilities)\n",
    "    df = pd_extend(df, pd.DataFrame(all_data, columns = df.columns))\n",
    "    idx = np.where(df[\"Recovered Alpha\"].values == None)\n",
    "    df[\"Recovered Alpha\"].values[idx] = res[0]\n",
    "    df[\"Recovered Beta\"].values[idx] = res[1]\n",
    "    df[\"Recovered Mu\"].values[idx] = res[2]\n",
    "    return *res, df\n",
    "\n",
    "def MLE_alpha_mu_LUCE(pairs, lotteries, certain_value, ambiguities, probabilities):\n",
    "    best_fit = None\n",
    "    max_likelihood = None\n",
    "    y, n = pairs[:, 0], pairs[:, 1]\n",
    "    idx = np.where(ambiguities == 0)\n",
    "    for alpha in np.round(np.arange( 0.3, 2.01, 0.01), 2): ## grid search - part 1 (fit alpha first)\n",
    "        for mu in np.round(np.arange(0.5, 0.71, 0.01), 2):\n",
    "            likelihood = np.nansum(binomial_likelihood_LUCE(alpha, 0, mu, y[idx], n[idx], lotteries[idx], certain_value, ambiguities[idx], probabilities[idx]))\n",
    "            if max_likelihood is None or likelihood > max_likelihood:\n",
    "                max_likelihood = likelihood\n",
    "                best_fit = (alpha, mu)\n",
    "    return best_fit\n",
    "\n",
    "def MLE_beta_LUCE(pairs, alpha, mu, lotteries, certain_value, ambiguities, probabilities):\n",
    "    best_fit = None\n",
    "    max_likelihood = None\n",
    "    y, n = pairs[:, 0], pairs[:, 1]\n",
    "    idx = np.where(ambiguities != 0)\n",
    "    for beta in np.round(np.arange(-1.3, 1.31, 0.01), 2): ## grid search - part 2 (fit beta second)\n",
    "        likelihood = np.nansum(binomial_likelihood_LUCE(alpha, beta, mu, y[idx], n[idx], lotteries[idx], certain_value, ambiguities[idx], probabilities[idx]))\n",
    "        if max_likelihood is None or likelihood > max_likelihood:\n",
    "            max_likelihood = likelihood\n",
    "            best_fit = (alpha, beta, mu)\n",
    "    return best_fit\n",
    "\n",
    "def probability_of_lottery_choice_LUCE(alpha, beta, mu, lottery_value, certain_value, ambiguity, probability):\n",
    "    SV_lottery, SV_certain = SVs(alpha, beta, lottery_value, certain_value, ambiguity, probability)\n",
    "    return SV_lottery**(1 / mu) / (SV_lottery**(1 / mu) + SV_certain**(1 / mu)), SV_lottery, SV_certain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Luce #1**\n",
    "- Simulating across beta and mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Participant parameter space (~10,000 simulated subs)\n",
    "alphas = np.array([0.6]) ## 1 step\n",
    "betas  = np.round(np.arange(-1.3, 1.31, 2.6/498), 3) ## 500 steps\n",
    "mus    = np.round(np.arange( 0.5,  0.7,    0.01), 2) ## 20 steps\n",
    "print(\"Number of Simulations:\", len(alphas)*len(betas)*len(mus))\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df_participants = pd.DataFrame(columns=[\"PID\", \n",
    "                                        \"Simulated Alpha\", \"Simulated Beta\", \"Simulated Mu\", \n",
    "                                        \"Recovered Alpha\", \"Recovered Beta\", \"Recovered Mu\",\n",
    "                                        \"Lottery Value\", \"Safe Value\", \n",
    "                                        \"Ambiguity\", \"Probability\",\n",
    "                                        \"SV Lottery\", \"SV Safe\", \n",
    "                                        \"Choice\"])\n",
    "pid = 1\n",
    "for p_mu in mus:\n",
    "    for p_alpha in alphas:\n",
    "        for p_beta in betas:\n",
    "            r_alpha, r_beta, r_mu, df_participants = make_data_and_recover_LUCE(p_alpha, p_beta, p_mu, pid, df_participants)\n",
    "            print(pid, end = \"\\r\")\n",
    "            pid += 1   \n",
    "filename = os.path.join(save_dir, \"simulation4LUCE_cAvBvM-2trials.csv\")\n",
    "df_participants.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = glob(os.path.join(base_proj_dir, save_dir, \"simulation4LUCE_cAvBvM-2trials.csv\"))[0]\n",
    "df = pd.read_csv(file)\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "beta_x = df[\"Simulated Beta\"].values[::total_trials]\n",
    "fit_line = linregress(beta_x, df[\"Recovered Beta\"].values[::total_trials])\n",
    "fit_stat = spearmanr(beta_x, df[\"Recovered Beta\"].values[::total_trials])\n",
    "line_y = np.array(beta_x) * fit_line.slope + fit_line.intercept\n",
    "residuals = np.array(beta_x) - df[\"Recovered Beta\"].values[::total_trials]\n",
    "print(\"Shapiro-Wilk Test of Normality:\", shapiro(np.abs(residuals))[:])\n",
    "print(\"Spearmans Rho^2:\", fit_stat[:])\n",
    "print(\"Residual SD:\", np.std(residuals))\n",
    "df2[\"Simulated β (Luce)\"] = df[\"Simulated Beta\"].values[::total_trials]\n",
    "df2[\"Fit β\"] = df[\"Recovered Beta\"].values[::total_trials]\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.regplot(x = \"Simulated β (Luce)\", y = \"Fit β\", data = df2, color = \"#D401B5\")\n",
    "sns.despine(top = True)\n",
    "ax.set_ylabel(\"Fit β\", fontsize = 16)\n",
    "ax.set_xlabel(\"Simulated β\", fontsize = 16)\n",
    "plt.suptitle(\"n={5} (α=0.6, μ=[0.5,0.7,0.01]) | Shapiro-Wilk={0:.2f}, p={1:.2f}** | Spearmans Rho^2={2:.2f}, p={3:.2f}** | Residual SD={4:.2f}\".format(shapiro(np.abs(residuals))[0], \n",
    "                                                                                                                                                        shapiro(np.abs(residuals))[1], \n",
    "                                                                                                                                                        fit_stat[0]**2, fit_stat[1], \n",
    "                                                                                                                                                        np.std(residuals), \n",
    "                                                                                                                                                        len(beta_x)), \n",
    "                                                                                                                                                        fontsize = 12)\n",
    "fig_name = os.path.join(save_dir, \"simulation4LUCE_cAvBvM-2trials.png\")\n",
    "print(\"Saving to: {}\".format(fig_name))\n",
    "plt.savefig(fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Luce #2**\n",
    "- Simulating across alpha, beta, and mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Participant parameter space (~180,000 simulated subs)\n",
    "alphas = np.round(np.arange( 0.3,  1.2,    0.05), 2)\n",
    "betas  = np.round(np.arange(-1.3, 1.31, 2.6/498), 3) ## 500 steps\n",
    "mus    = np.round(np.arange( 0.5,  0.7,    0.01), 2) ## 20 steps\n",
    "print(\"Number of Simulations:\", len(alphas)*len(betas)*len(mus))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df_participants = pd.DataFrame(columns=[\"PID\", \n",
    "                                        \"Simulated Alpha\", \"Simulated Beta\", \"Simulated Mu\", \n",
    "                                        \"Recovered Alpha\", \"Recovered Beta\", \"Recovered Mu\",\n",
    "                                        \"Lottery Value\", \"Safe Value\", \n",
    "                                        \"Ambiguity\", \"Probability\",\n",
    "                                        \"SV Lottery\", \"SV Safe\",\n",
    "                                        \"Choice\"])\n",
    "pid = 1\n",
    "for p_mu in mus:\n",
    "    for p_alpha in alphas:\n",
    "        for p_beta in betas:\n",
    "            r_alpha, r_beta, r_mu, df_participants = make_data_and_recover_LUCE(p_alpha, p_beta, p_mu, pid, df_participants)\n",
    "            print(pid, end = \"\\r\")\n",
    "            pid += 1  \n",
    "filename = os.path.join(save_dir, \"simulation4LUCE_vAvBvM-2trials.csv\")\n",
    "df_participants.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = glob(os.path.join(base_proj_dir, save_dir, \"simulation4LUCE_vAvBvM-2trials.csv\"))[0]\n",
    "df = pd.read_csv(file)\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "beta_x = df[\"Simulated Beta\"].values[::total_trials]\n",
    "fit_line = linregress(beta_x, df[\"Recovered Beta\"].values[::total_trials])\n",
    "fit_stat = spearmanr(beta_x, df[\"Recovered Beta\"].values[::total_trials])\n",
    "line_y = np.array(beta_x) * fit_line.slope + fit_line.intercept\n",
    "residuals = np.array(beta_x) - df[\"Recovered Beta\"].values[::total_trials]\n",
    "print(\"Shapiro-Wilk Test of Normality:\", shapiro(np.abs(residuals))[:])\n",
    "print(\"Spearmans Rho^2:\", fit_stat[:])\n",
    "print(\"Residual SD:\", np.std(residuals))\n",
    "df2[\"Simulated β (Luce)\"] = df[\"Simulated Beta\"].values[::total_trials]\n",
    "df2[\"Fit β\"] = df[\"Recovered Beta\"].values[::total_trials]\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.regplot(x = \"Simulated β (Luce)\", y = \"Fit β\", data = df2, color = \"#E15930\")\n",
    "sns.despine(top = True)\n",
    "ax.set_ylabel(\"Fit β\", fontsize = 16)\n",
    "ax.set_xlabel(\"Simulated β (Luce)\", fontsize = 16)\n",
    "plt.suptitle(\"n={5} (α[0.3,1.2,0.05], μ=[0.5,0.7,0.01]) | Shapiro-Wilk={0:.2f}, p={1:.2f}** | Spearmans Rho^2={2:.2f}, p={3:.2f}** | Residual SD={4:.2f}\".format(shapiro(np.abs(residuals))[0], \n",
    "                                                                                                                                                                shapiro(np.abs(residuals))[1], \n",
    "                                                                                                                                                                fit_stat[0], fit_stat[1], \n",
    "                                                                                                                                                                np.std(residuals)), \n",
    "                                                                                                                                                                len(beta_x), \n",
    "                                                                                                                                                                fontsize = 12)\n",
    "fig_name = os.path.join(save_dir, \"simulation4LUCE_vAvBvM-2trials.png\")\n",
    "print(\"Saving to: {}\".format(fig_name))\n",
    "plt.savefig(fig_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
